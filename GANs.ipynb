{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emrehangorgec/GANsNFTs/blob/main/GANs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaT1x3C6h6z6"
      },
      "source": [
        "# StyleGAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGQQ-6d3vjFx",
        "outputId": "a9307baa-630a-45c3-a241-57125b1c1928",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'stylegan3'...\n",
            "remote: Enumerating objects: 212, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 212 (delta 0), reused 1 (delta 0), pack-reused 207\u001b[K\n",
            "Receiving objects: 100% (212/212), 4.17 MiB | 9.85 MiB/s, done.\n",
            "Resolving deltas: 100% (98/98), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/NVlabs/stylegan3.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxPRbcZWi4rZ",
        "outputId": "7aa22710-f38b-4d79-8608-29b457ce438a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stylegan3\n"
          ]
        }
      ],
      "source": [
        "%cd stylegan3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1b10dX8qcgO",
        "outputId": "730cc346-e652-4a63-b7de-115318b40285"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-04-04 19:51:52--  https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-t-ffhq-1024x1024.pkl\n",
            "Resolving api.ngc.nvidia.com (api.ngc.nvidia.com)... 34.212.239.79, 35.167.170.225\n",
            "Connecting to api.ngc.nvidia.com (api.ngc.nvidia.com)|34.212.239.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://files.ngc.nvidia.com/org/nvidia/team/research/models/stylegan3/versions/1/files/stylegan3-t-ffhq-1024x1024.pkl?Expires=1712263913&Signature=zVziK0vRWpXI6PmPoN41avSMA7kL0UzN8cy2NRuF8Rs7AsFjfXdCZjn78AOSNvEtFUwNuBW9uKtLcssHiNXFPuZ67FPV-EixtmsDoP6mR~MQy10MXdsH52i1Iw9KrwiQcZ96zULqDRXRnetOSwTIsfG2MMdNLLl1B38OhReZOdXs5ipIfLtCTxmsAf-9bAYSE1yVsU5Lua9wiyTw1B5LHvyPczgmpM3WaOgyi7wrW7I6v4bS0V2rU6UheGDMg1-xLZo4LUXqE5Erd-QjEXLxmRbD6b2MJEBvx1W1oKJZHWE3942DP-FQ7OSSOuhNhiZX9cpALGxhTgwziPuCuoNB4w__&Key-Pair-Id=KCX06E8E9L60W [following]\n",
            "--2024-04-04 19:51:53--  https://files.ngc.nvidia.com/org/nvidia/team/research/models/stylegan3/versions/1/files/stylegan3-t-ffhq-1024x1024.pkl?Expires=1712263913&Signature=zVziK0vRWpXI6PmPoN41avSMA7kL0UzN8cy2NRuF8Rs7AsFjfXdCZjn78AOSNvEtFUwNuBW9uKtLcssHiNXFPuZ67FPV-EixtmsDoP6mR~MQy10MXdsH52i1Iw9KrwiQcZ96zULqDRXRnetOSwTIsfG2MMdNLLl1B38OhReZOdXs5ipIfLtCTxmsAf-9bAYSE1yVsU5Lua9wiyTw1B5LHvyPczgmpM3WaOgyi7wrW7I6v4bS0V2rU6UheGDMg1-xLZo4LUXqE5Erd-QjEXLxmRbD6b2MJEBvx1W1oKJZHWE3942DP-FQ7OSSOuhNhiZX9cpALGxhTgwziPuCuoNB4w__&Key-Pair-Id=KCX06E8E9L60W\n",
            "Resolving files.ngc.nvidia.com (files.ngc.nvidia.com)... 52.84.229.81, 52.84.229.12, 52.84.229.14, ...\n",
            "Connecting to files.ngc.nvidia.com (files.ngc.nvidia.com)|52.84.229.81|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 294775112 (281M) [application/x-zerosize]\n",
            "Saving to: ‘stylegan3-t-ffhq-1024x1024.pkl’\n",
            "\n",
            "stylegan3-t-ffhq-10 100%[===================>] 281.12M  76.7MB/s    in 3.6s    \n",
            "\n",
            "2024-04-04 19:51:58 (78.2 MB/s) - ‘stylegan3-t-ffhq-1024x1024.pkl’ saved [294775112/294775112]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-t-ffhq-1024x1024.pkl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWW1lNKUq0i7",
        "outputId": "06c02bd8-d789-49a2-9567-ad7fe10a5d5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ninja\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/307.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/307.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.11.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install ninja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CG-YiZI5rr9P",
        "outputId": "2fb01b88-17bc-4196-8e90-461b670d8630"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "avg_spectra.py\t docs\t\t  legacy.py    stylegan3-t-ffhq-1024x1024.pkl  visualizer.py\n",
            "calc_metrics.py  environment.yml  LICENSE.txt  stylegan3-t-ffhqu-256x256.pkl   viz\n",
            "dataset_tool.py  gen_images.py\t  metrics      torch_utils\n",
            "dnnlib\t\t gen_video.py\t  __pycache__  training\n",
            "Dockerfile\t gui_utils\t  README.md    train.py\n"
          ]
        }
      ],
      "source": [
        "!ls /content/stylegan3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DGVuKVbsGqD",
        "outputId": "c0386ac6-fc63-44ed-fd7e-3199584e698a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading networks from \"https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-r-ffhq-1024x1024.pkl\"...\n",
            "Downloading https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-r-ffhq-1024x1024.pkl ... done\n",
            "Generating image for seed 6600 (0/26) ...\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "Generating image for seed 6601 (1/26) ...\n",
            "Generating image for seed 6602 (2/26) ...\n",
            "Generating image for seed 6603 (3/26) ...\n",
            "Generating image for seed 6604 (4/26) ...\n",
            "Generating image for seed 6605 (5/26) ...\n",
            "Generating image for seed 6606 (6/26) ...\n",
            "Generating image for seed 6607 (7/26) ...\n",
            "Generating image for seed 6608 (8/26) ...\n",
            "Generating image for seed 6609 (9/26) ...\n",
            "Generating image for seed 6610 (10/26) ...\n",
            "Generating image for seed 6611 (11/26) ...\n",
            "Generating image for seed 6612 (12/26) ...\n",
            "Generating image for seed 6613 (13/26) ...\n",
            "Generating image for seed 6614 (14/26) ...\n",
            "Generating image for seed 6615 (15/26) ...\n",
            "Generating image for seed 6616 (16/26) ...\n",
            "Generating image for seed 6617 (17/26) ...\n",
            "Generating image for seed 6618 (18/26) ...\n",
            "Generating image for seed 6619 (19/26) ...\n",
            "Generating image for seed 6620 (20/26) ...\n",
            "Generating image for seed 6621 (21/26) ...\n",
            "Generating image for seed 6622 (22/26) ...\n",
            "Generating image for seed 6623 (23/26) ...\n",
            "Generating image for seed 6624 (24/26) ...\n",
            "Generating image for seed 6625 (25/26) ...\n"
          ]
        }
      ],
      "source": [
        "# HIDE OUTPUT\n",
        "URL = \"https://api.ngc.nvidia.com/v2/models/nvidia/research/\"\\\n",
        "      \"stylegan3/versions/1/files/stylegan3-r-ffhq-1024x1024.pkl\"\n",
        "_URL = \"https://api.ngc.nvidia.com/v2/models/org/nvidia/team/research/stylegan3/1/files?redirect=true&path=stylegan3-r-afhqv2-512x512.pkl\"\n",
        "\n",
        "!python /content/stylegan3/gen_images.py \\\n",
        "    --network={_URL} \\\n",
        "  --outdir=/content/results --seeds=6600-6625"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUZTgQlDvrLC",
        "outputId": "d11b71a0-185a-4c5f-9dcf-a35e737c1ff3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading networks from \"https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-r-afhqv2-512x512.pkl\"...\n",
            "Downloading https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-r-afhqv2-512x512.pkl ... done\n",
            "Generating image for seed 6626 (0/5) ...\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "Generating image for seed 6627 (1/5) ...\n",
            "Generating image for seed 6628 (2/5) ...\n",
            "Generating image for seed 6629 (3/5) ...\n",
            "Generating image for seed 6630 (4/5) ...\n"
          ]
        }
      ],
      "source": [
        "# HIDE OUTPUT\n",
        "URL = \"https://api.ngc.nvidia.com/v2/models/nvidia/research/\"\\\n",
        "      \"stylegan3/versions/1/files/stylegan3-r-ffhq-1024x1024.pkl\"\n",
        "_URL = \"https://api.ngc.nvidia.com/v2/models/nvidia/research/\"\\\n",
        "      \"stylegan3/versions/1/files/stylegan3-r-afhqv2-512x512.pkl\"\n",
        "\n",
        "!python /content/stylegan3/gen_images.py \\\n",
        "    --network={_URL} \\\n",
        "  --outdir=/content/results --seeds=6626-6630"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXHX6sJl8sEj"
      },
      "source": [
        "## **Trainign our own dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VW4SK1aj8uKe",
        "outputId": "883262c0-a64f-4397-86d0-1ed50c7fbc2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Apr 16 14:02:27 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBS7yEh1GnwX",
        "outputId": "392f587e-c747-4d6f-ac73-36b16a7145ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omvz9531X_VM",
        "outputId": "dd4c6891-5d65-499e-91b8-6e828f58bbd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100% 560/560 [00:14<00:00, 38.70it/s]\n"
          ]
        }
      ],
      "source": [
        "CMD = \"python /content/stylegan2-ada-pytorch/dataset_tool.py \"\\\n",
        "  \"--source /content/drive/MyDrive/GANsNFTs/StyleGAN/data/gan/images \"\\\n",
        "  \"--dest /content/drive/MyDrive/GANsNFTs/StyleGAN/data/gan/dataset/portraits\"\n",
        "\n",
        "!{CMD}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "HSdv6JPTbhCk",
        "outputId": "4583af28-9566-456c-a53a-0b5ec42927ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: torch 1.11.0\n",
            "Uninstalling torch-1.11.0:\n",
            "  Successfully uninstalled torch-1.11.0\n",
            "Found existing installation: torchvision 0.12.0\n",
            "Uninstalling torchvision-0.12.0:\n",
            "  Successfully uninstalled torchvision-0.12.0\n",
            "\u001b[33mWARNING: Skipping torchaudio as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting torch==1.11.0\n",
            "  Using cached torch-1.11.0-cp310-cp310-manylinux1_x86_64.whl (750.6 MB)\n",
            "Collecting torchvision==0.12.0\n",
            "  Using cached torchvision-0.12.0-cp310-cp310-manylinux1_x86_64.whl (21.0 MB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.11.0) (4.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0) (9.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0) (2024.2.2)\n",
            "Installing collected packages: torch, torchvision\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchdata 0.7.1 requires torch>=2, but you have torch 1.11.0 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 1.11.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.11.0 torchvision-0.12.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "f957f9c57c71481083e56ab62463f96b",
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip uninstall torch torchvision torchaudio -y\n",
        "!pip install torch==1.11.0 torchvision==0.12.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjV8kXTQl0eo",
        "outputId": "c230ea64-1d22-4602-c450-d5c278b79e57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.11.0+cu102\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQQHuJ60oDr9",
        "outputId": "424fe122-ed87-40b2-c431-cc6ef854e9d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"num_gpus\": 1,\n",
            "  \"image_snapshot_ticks\": 10,\n",
            "  \"network_snapshot_ticks\": 10,\n",
            "  \"metrics\": [\n",
            "    \"fid50k_full\"\n",
            "  ],\n",
            "  \"random_seed\": 0,\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"/content/drive/MyDrive/GANsNFTs/StyleGAN/data/gan/dataset/portraits\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 560,\n",
            "    \"xflip\": false,\n",
            "    \"resolution\": 64\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"num_workers\": 3,\n",
            "    \"prefetch_factor\": 2\n",
            "  },\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"synthesis_kwargs\": {\n",
            "      \"channel_base\": 16384,\n",
            "      \"channel_max\": 512,\n",
            "      \"num_fp16_res\": 4,\n",
            "      \"conv_clamp\": 256\n",
            "    }\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Discriminator\",\n",
            "    \"block_kwargs\": {},\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 16384,\n",
            "    \"channel_max\": 512,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.0025,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.0025,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 0.0256\n",
            "  },\n",
            "  \"total_kimg\": 25000,\n",
            "  \"batch_size\": 32,\n",
            "  \"batch_gpu\": 32,\n",
            "  \"ema_kimg\": 10.0,\n",
            "  \"ema_rampup\": 0.05,\n",
            "  \"ada_target\": 0.6,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1,\n",
            "    \"brightness\": 1,\n",
            "    \"contrast\": 1,\n",
            "    \"lumaflip\": 1,\n",
            "    \"hue\": 1,\n",
            "    \"saturation\": 1\n",
            "  },\n",
            "  \"run_dir\": \"/content/drive/MyDrive/GANsNFTs/StyleGAN/data/gan/experiments/00001-portraits-auto1\"\n",
            "}\n",
            "\n",
            "Output directory:   /content/drive/MyDrive/GANsNFTs/StyleGAN/data/gan/experiments/00001-portraits-auto1\n",
            "Training data:      /content/drive/MyDrive/GANsNFTs/StyleGAN/data/gan/dataset/portraits\n",
            "Training duration:  25000 kimg\n",
            "Number of GPUs:     1\n",
            "Number of images:   560\n",
            "Image resolution:   64\n",
            "Conditional model:  False\n",
            "Dataset x-flips:    False\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/stylegan2-ada-pytorch/train.py\", line 538, in <module>\n",
            "    main() # pylint: disable=no-value-for-parameter\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1157, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1078, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1434, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 783, in invoke\n",
            "    return __callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/decorators.py\", line 33, in new_func\n",
            "    return f(get_current_context(), *args, **kwargs)\n",
            "  File \"/content/stylegan2-ada-pytorch/train.py\", line 528, in main\n",
            "    torch.multiprocessing.set_start_method('spawn')\n",
            "  File \"/usr/lib/python3.10/multiprocessing/context.py\", line 247, in set_start_method\n",
            "    raise RuntimeError('context has already been set')\n",
            "RuntimeError: context has already been set\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch.multiprocessing\n",
        "import multiprocessing\n",
        "\n",
        "if multiprocessing.get_start_method(allow_none=True) != 'spawn':\n",
        "    torch.multiprocessing.set_start_method('spawn', force=True)\n",
        "\n",
        "# Modify these to suit your needs\n",
        "EXPERIMENTS = \"/content/drive/MyDrive/GANsNFTs/StyleGAN/data/gan/experiments\"\n",
        "DATA = \"/content/drive/MyDrive/GANsNFTs/StyleGAN/data/gan/dataset/portraits\"\n",
        "SNAP = 10\n",
        "\n",
        "# Build the command and run it\n",
        "cmd = f\"/usr/bin/python3 /content/stylegan2-ada-pytorch/train.py \"\\\n",
        "  f\"--snap {SNAP} --outdir {EXPERIMENTS} --data {DATA}\"\n",
        "!{cmd}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddq4g96OoVwW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voPSnBS8tqVj"
      },
      "source": [
        "## **StyleGAN3 Deneme**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXMqbk8Czo-5",
        "outputId": "f101d793-55f1-418c-d73a-c4438104d696"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'stylegan3'...\n",
            "remote: Enumerating objects: 212, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 212 (delta 0), reused 1 (delta 0), pack-reused 207\u001b[K\n",
            "Receiving objects: 100% (212/212), 4.16 MiB | 8.48 MiB/s, done.\n",
            "Resolving deltas: 100% (101/101), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/NVlabs/stylegan3.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NhQ3TgLzrKi",
        "outputId": "dc20e8b5-e5af-4cfc-9b49-847f86f0a63e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/stylegan3\n"
          ]
        }
      ],
      "source": [
        "%cd /content/stylegan3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cq09HVnlz05z",
        "outputId": "e707c382-4acd-4dc2-a825-d51f02fdf0cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.2.1+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztfmKjwa7-Uh",
        "outputId": "d5990a9b-4c69-491f-8284-795ff3ea7ff0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ninja\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/307.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m235.5/307.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.11.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install ninja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGb65osA0Zh-",
        "outputId": "7a8cd122-7ad2-408a-c81d-3d6b065659aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100% 560/560 [00:02<00:00, 264.79it/s]\n"
          ]
        }
      ],
      "source": [
        "!python dataset_tool.py --source=/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/images --dest=/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/dataset/portraits.zip --resolution='64x64'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPQASpMA1gBR",
        "outputId": "b2f2c1ed-7ef7-4bb4-fee1-f18a4d1f5fdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan3.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"magnitude_ema_beta\": 0.9988915792636801\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan2.Discriminator\",\n",
            "    \"block_kwargs\": {\n",
            "      \"freeze_layers\": 0\n",
            "    },\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.0025\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 6.6\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"prefetch_factor\": 2,\n",
            "    \"num_workers\": 3\n",
            "  },\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/dataset/portraits.zip\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 560,\n",
            "    \"xflip\": true,\n",
            "    \"resolution\": 64,\n",
            "    \"random_seed\": 0\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"batch_size\": 32,\n",
            "  \"batch_gpu\": 16,\n",
            "  \"metrics\": [\n",
            "    \"fid50k_full\"\n",
            "  ],\n",
            "  \"total_kimg\": 500,\n",
            "  \"kimg_per_tick\": 4,\n",
            "  \"image_snapshot_ticks\": 50,\n",
            "  \"network_snapshot_ticks\": 50,\n",
            "  \"random_seed\": 0,\n",
            "  \"ema_kimg\": 10.0,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1,\n",
            "    \"brightness\": 1,\n",
            "    \"contrast\": 1,\n",
            "    \"lumaflip\": 1,\n",
            "    \"hue\": 1,\n",
            "    \"saturation\": 1\n",
            "  },\n",
            "  \"ada_target\": 0.6,\n",
            "  \"run_dir\": \"~/training-runs/00001-stylegan3-t-portraits-gpus1-batch32-gamma6.6\"\n",
            "}\n",
            "\n",
            "Output directory:    ~/training-runs/00001-stylegan3-t-portraits-gpus1-batch32-gamma6.6\n",
            "Number of GPUs:      1\n",
            "Batch size:          32 images\n",
            "Training duration:   500 kimg\n",
            "Dataset path:        /content/drive/MyDrive/GANsNFTs/StyleGAN/gan/dataset/portraits.zip\n",
            "Dataset size:        560 images\n",
            "Dataset resolution:  64\n",
            "Dataset labels:      False\n",
            "Dataset x-flips:     True\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/sampler.py:64: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
            "  warnings.warn(\"`data_source` argument is not used and will be removed in 2.2.0.\"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "Num images:  1120\n",
            "Image shape: [3, 64, 64]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "\n",
            "Generator                    Parameters  Buffers  Output shape       Datatype\n",
            "---                          ---         ---      ---                ---     \n",
            "mapping.fc0                  262656      -        [16, 512]          float32 \n",
            "mapping.fc1                  262656      -        [16, 512]          float32 \n",
            "mapping                      -           512      [16, 16, 512]      float32 \n",
            "synthesis.input.affine       2052        -        [16, 4]            float32 \n",
            "synthesis.input              262144      1545     [16, 512, 36, 36]  float32 \n",
            "synthesis.L0_36_512.affine   262656      -        [16, 512]          float32 \n",
            "synthesis.L0_36_512          2359808     25       [16, 512, 36, 36]  float16 \n",
            "synthesis.L1_36_512.affine   262656      -        [16, 512]          float32 \n",
            "synthesis.L1_36_512          2359808     25       [16, 512, 36, 36]  float16 \n",
            "synthesis.L2_36_512.affine   262656      -        [16, 512]          float32 \n",
            "synthesis.L2_36_512          2359808     25       [16, 512, 36, 36]  float16 \n",
            "synthesis.L3_36_512.affine   262656      -        [16, 512]          float32 \n",
            "synthesis.L3_36_512          2359808     25       [16, 512, 36, 36]  float16 \n",
            "synthesis.L4_52_512.affine   262656      -        [16, 512]          float32 \n",
            "synthesis.L4_52_512          2359808     37       [16, 512, 52, 52]  float16 \n",
            "synthesis.L5_52_512.affine   262656      -        [16, 512]          float32 \n",
            "synthesis.L5_52_512          2359808     25       [16, 512, 52, 52]  float16 \n",
            "synthesis.L6_52_512.affine   262656      -        [16, 512]          float32 \n",
            "synthesis.L6_52_512          2359808     25       [16, 512, 52, 52]  float16 \n",
            "synthesis.L7_52_512.affine   262656      -        [16, 512]          float32 \n",
            "synthesis.L7_52_512          2359808     25       [16, 512, 52, 52]  float16 \n",
            "synthesis.L8_84_512.affine   262656      -        [16, 512]          float32 \n",
            "synthesis.L8_84_512          2359808     37       [16, 512, 84, 84]  float16 \n",
            "synthesis.L9_84_512.affine   262656      -        [16, 512]          float32 \n",
            "synthesis.L9_84_512          2359808     25       [16, 512, 84, 84]  float16 \n",
            "synthesis.L10_84_512.affine  262656      -        [16, 512]          float32 \n",
            "synthesis.L10_84_512         2359808     25       [16, 512, 84, 84]  float16 \n",
            "synthesis.L11_84_512.affine  262656      -        [16, 512]          float32 \n",
            "synthesis.L11_84_512         2359808     25       [16, 512, 84, 84]  float16 \n",
            "synthesis.L12_84_512.affine  262656      -        [16, 512]          float32 \n",
            "synthesis.L12_84_512         2359808     25       [16, 512, 84, 84]  float16 \n",
            "synthesis.L13_64_512.affine  262656      -        [16, 512]          float32 \n",
            "synthesis.L13_64_512         2359808     25       [16, 512, 64, 64]  float16 \n",
            "synthesis.L14_64_3.affine    262656      -        [16, 512]          float32 \n",
            "synthesis.L14_64_3           1539        1        [16, 3, 64, 64]    float16 \n",
            "synthesis                    -           -        [16, 3, 64, 64]    float32 \n",
            "---                          ---         ---      ---                ---     \n",
            "Total                        37768199    2432     -                  -       \n",
            "\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape       Datatype\n",
            "---            ---         ---      ---                ---     \n",
            "b64.fromrgb    2048        16       [16, 512, 64, 64]  float16 \n",
            "b64.skip       262144      16       [16, 512, 32, 32]  float16 \n",
            "b64.conv0      2359808     16       [16, 512, 64, 64]  float16 \n",
            "b64.conv1      2359808     16       [16, 512, 32, 32]  float16 \n",
            "b64            -           16       [16, 512, 32, 32]  float16 \n",
            "b32.skip       262144      16       [16, 512, 16, 16]  float16 \n",
            "b32.conv0      2359808     16       [16, 512, 32, 32]  float16 \n",
            "b32.conv1      2359808     16       [16, 512, 16, 16]  float16 \n",
            "b32            -           16       [16, 512, 16, 16]  float16 \n",
            "b16.skip       262144      16       [16, 512, 8, 8]    float16 \n",
            "b16.conv0      2359808     16       [16, 512, 16, 16]  float16 \n",
            "b16.conv1      2359808     16       [16, 512, 8, 8]    float16 \n",
            "b16            -           16       [16, 512, 8, 8]    float16 \n",
            "b8.skip        262144      16       [16, 512, 4, 4]    float16 \n",
            "b8.conv0       2359808     16       [16, 512, 8, 8]    float16 \n",
            "b8.conv1       2359808     16       [16, 512, 4, 4]    float16 \n",
            "b8             -           16       [16, 512, 4, 4]    float16 \n",
            "b4.mbstd       -           -        [16, 513, 4, 4]    float32 \n",
            "b4.conv        2364416     16       [16, 512, 4, 4]    float32 \n",
            "b4.fc          4194816     -        [16, 512]          float32 \n",
            "b4.out         513         -        [16, 1]            float32 \n",
            "---            ---         ---      ---                ---     \n",
            "Total          26488833    288      -                  -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "2024-04-07 19:06:33.350070: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-07 19:06:33.350131: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-07 19:06:33.351390: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-07 19:06:34.531480: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Training for 500 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      time 4m 57s       sec/tick 6.7     sec/kimg 210.33  maintenance 290.4  cpumem 2.11   gpumem 13.70  reserved 14.65  augment 0.000\n",
            "Evaluating metrics...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "{\"results\": {\"fid50k_full\": 3.5669314760007385e+95}, \"metric\": \"fid50k_full\", \"total_time\": 519.2758524417877, \"total_time_str\": \"8m 39s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000000.pkl\", \"timestamp\": 1712517332.4346437}\n",
            "tick 1     kimg 4.0      time 16m 09s      sec/tick 142.1   sec/kimg 35.52   maintenance 530.3  cpumem 2.69   gpumem 6.24   reserved 7.15   augment 0.000\n",
            "tick 2     kimg 8.0      time 18m 32s      sec/tick 142.6   sec/kimg 35.66   maintenance 0.0    cpumem 2.69   gpumem 6.24   reserved 7.15   augment 0.005\n",
            "tick 3     kimg 12.0     time 20m 55s      sec/tick 142.6   sec/kimg 35.66   maintenance 0.0    cpumem 2.69   gpumem 6.24   reserved 7.15   augment 0.010\n",
            "tick 4     kimg 16.0     time 23m 18s      sec/tick 142.9   sec/kimg 35.72   maintenance 0.0    cpumem 2.69   gpumem 6.24   reserved 7.15   augment 0.017\n",
            "tick 5     kimg 20.0     time 25m 40s      sec/tick 142.4   sec/kimg 35.60   maintenance 0.0    cpumem 2.69   gpumem 6.24   reserved 7.15   augment 0.021\n",
            "tick 6     kimg 24.0     time 28m 02s      sec/tick 142.4   sec/kimg 35.59   maintenance 0.0    cpumem 2.69   gpumem 6.24   reserved 7.15   augment 0.026\n",
            "tick 7     kimg 28.0     time 30m 29s      sec/tick 146.3   sec/kimg 36.57   maintenance 0.0    cpumem 2.69   gpumem 6.24   reserved 7.15   augment 0.026\n",
            "tick 8     kimg 32.0     time 32m 52s      sec/tick 143.0   sec/kimg 35.76   maintenance 0.0    cpumem 2.69   gpumem 6.24   reserved 7.15   augment 0.026\n",
            "\n",
            "Aborted!\n"
          ]
        }
      ],
      "source": [
        "!python /content/stylegan3/train.py --outdir=~/training-runs --cfg=stylegan3-t --data=/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/dataset/portraits.zip \\\n",
        "    --gpus=1 --batch=32 --batch-gpu=16 --gamma=6.6 --mirror=1 --kimg=500 --snap=50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9tyHnhrI4-R",
        "outputId": "409c0a12-c58f-4e48-abe0-15c3ffa8f87d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan3.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"magnitude_ema_beta\": 0.9988915792636801\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan2.Discriminator\",\n",
            "    \"block_kwargs\": {\n",
            "      \"freeze_layers\": 0\n",
            "    },\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.0025\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 6.6\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"prefetch_factor\": 2,\n",
            "    \"num_workers\": 3\n",
            "  },\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/dataset/portraits.zip\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 560,\n",
            "    \"xflip\": true,\n",
            "    \"resolution\": 64,\n",
            "    \"random_seed\": 0\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"batch_size\": 32,\n",
            "  \"batch_gpu\": 16,\n",
            "  \"metrics\": [],\n",
            "  \"total_kimg\": 500,\n",
            "  \"kimg_per_tick\": 4,\n",
            "  \"image_snapshot_ticks\": 50,\n",
            "  \"network_snapshot_ticks\": 50,\n",
            "  \"random_seed\": 0,\n",
            "  \"ema_kimg\": 10.0,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1,\n",
            "    \"brightness\": 1,\n",
            "    \"contrast\": 1,\n",
            "    \"lumaflip\": 1,\n",
            "    \"hue\": 1,\n",
            "    \"saturation\": 1\n",
            "  },\n",
            "  \"ada_target\": 0.6,\n",
            "  \"run_dir\": \"/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/experiments/training-runs/00000-stylegan3-t-portraits-gpus1-batch32-gamma6.6\"\n",
            "}\n",
            "\n",
            "Output directory:    /content/drive/MyDrive/GANsNFTs/StyleGAN/gan/experiments/training-runs/00000-stylegan3-t-portraits-gpus1-batch32-gamma6.6\n",
            "Number of GPUs:      1\n",
            "Batch size:          32 images\n",
            "Training duration:   500 kimg\n",
            "Dataset path:        /content/drive/MyDrive/GANsNFTs/StyleGAN/gan/dataset/portraits.zip\n",
            "Dataset size:        560 images\n",
            "Dataset resolution:  64\n",
            "Dataset labels:      False\n",
            "Dataset x-flips:     True\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/sampler.py:64: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
            "  warnings.warn(\"`data_source` argument is not used and will be removed in 2.2.0.\"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "Num images:  1120\n",
            "Image shape: [3, 64, 64]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "\n",
            "Generator                    Parameters  Buffers  Output shape       Datatype\n",
            "---                          ---         ---      ---                ---     \n",
            "mapping.fc0                  262656      -        [16, 512]          float32 \n",
            "mapping.fc1                  262656      -        [16, 512]          float32 \n",
            "mapping                      -           512      [16, 16, 512]      float32 \n",
            "synthesis.input.affine       2052        -        [16, 4]            float32 \n",
            "synthesis.input              262144      1545     [16, 512, 36, 36]  float32 \n",
            "synthesis.L0_36_512.affine   262656      -        [16, 512]          float32 \n",
            "synthesis.L0_36_512          2359808     25       [16, 512, 36, 36]  float16 \n",
            "synthesis.L1_36_512.affine   262656      -        [16, 512]          float32 \n",
            "synthesis.L1_36_512          2359808     25       [16, 512, 36, 36]  float16 \n",
            "synthesis.L2_36_512.affine   262656      -        [16, 512]          float32 \n",
            "synthesis.L2_36_512          2359808     25       [16, 512, 36, 36]  float16 \n",
            "synthesis.L3_36_512.affine   262656      -        [16, 512]          float32 \n",
            "synthesis.L3_36_512          2359808     25       [16, 512, 36, 36]  float16 \n",
            "synthesis.L4_52_512.affine   262656      -        [16, 512]          float32 \n",
            "synthesis.L4_52_512          2359808     37       [16, 512, 52, 52]  float16 \n",
            "synthesis.L5_52_512.affine   262656      -        [16, 512]          float32 \n",
            "synthesis.L5_52_512          2359808     25       [16, 512, 52, 52]  float16 \n",
            "synthesis.L6_52_512.affine   262656      -        [16, 512]          float32 \n",
            "synthesis.L6_52_512          2359808     25       [16, 512, 52, 52]  float16 \n",
            "synthesis.L7_52_512.affine   262656      -        [16, 512]          float32 \n",
            "synthesis.L7_52_512          2359808     25       [16, 512, 52, 52]  float16 \n",
            "synthesis.L8_84_512.affine   262656      -        [16, 512]          float32 \n",
            "synthesis.L8_84_512          2359808     37       [16, 512, 84, 84]  float16 \n",
            "synthesis.L9_84_512.affine   262656      -        [16, 512]          float32 \n",
            "synthesis.L9_84_512          2359808     25       [16, 512, 84, 84]  float16 \n",
            "synthesis.L10_84_512.affine  262656      -        [16, 512]          float32 \n",
            "synthesis.L10_84_512         2359808     25       [16, 512, 84, 84]  float16 \n",
            "synthesis.L11_84_512.affine  262656      -        [16, 512]          float32 \n",
            "synthesis.L11_84_512         2359808     25       [16, 512, 84, 84]  float16 \n",
            "synthesis.L12_84_512.affine  262656      -        [16, 512]          float32 \n",
            "synthesis.L12_84_512         2359808     25       [16, 512, 84, 84]  float16 \n",
            "synthesis.L13_64_512.affine  262656      -        [16, 512]          float32 \n",
            "synthesis.L13_64_512         2359808     25       [16, 512, 64, 64]  float16 \n",
            "synthesis.L14_64_3.affine    262656      -        [16, 512]          float32 \n",
            "synthesis.L14_64_3           1539        1        [16, 3, 64, 64]    float16 \n",
            "synthesis                    -           -        [16, 3, 64, 64]    float32 \n",
            "---                          ---         ---      ---                ---     \n",
            "Total                        37768199    2432     -                  -       \n",
            "\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape       Datatype\n",
            "---            ---         ---      ---                ---     \n",
            "b64.fromrgb    2048        16       [16, 512, 64, 64]  float16 \n",
            "b64.skip       262144      16       [16, 512, 32, 32]  float16 \n",
            "b64.conv0      2359808     16       [16, 512, 64, 64]  float16 \n",
            "b64.conv1      2359808     16       [16, 512, 32, 32]  float16 \n",
            "b64            -           16       [16, 512, 32, 32]  float16 \n",
            "b32.skip       262144      16       [16, 512, 16, 16]  float16 \n",
            "b32.conv0      2359808     16       [16, 512, 32, 32]  float16 \n",
            "b32.conv1      2359808     16       [16, 512, 16, 16]  float16 \n",
            "b32            -           16       [16, 512, 16, 16]  float16 \n",
            "b16.skip       262144      16       [16, 512, 8, 8]    float16 \n",
            "b16.conv0      2359808     16       [16, 512, 16, 16]  float16 \n",
            "b16.conv1      2359808     16       [16, 512, 8, 8]    float16 \n",
            "b16            -           16       [16, 512, 8, 8]    float16 \n",
            "b8.skip        262144      16       [16, 512, 4, 4]    float16 \n",
            "b8.conv0       2359808     16       [16, 512, 8, 8]    float16 \n",
            "b8.conv1       2359808     16       [16, 512, 4, 4]    float16 \n",
            "b8             -           16       [16, 512, 4, 4]    float16 \n",
            "b4.mbstd       -           -        [16, 513, 4, 4]    float32 \n",
            "b4.conv        2364416     16       [16, 512, 4, 4]    float32 \n",
            "b4.fc          4194816     -        [16, 512]          float32 \n",
            "b4.out         513         -        [16, 1]            float32 \n",
            "---            ---         ---      ---                ---     \n",
            "Total          26488833    288      -                  -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "2024-04-07 20:01:40.899174: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-07 20:01:40.899232: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-07 20:01:40.900631: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-07 20:01:42.139421: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Training for 500 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      time 31s          sec/tick 5.7     sec/kimg 176.98  maintenance 25.1   cpumem 2.08   gpumem 13.70  reserved 14.65  augment 0.000\n",
            "tick 1     kimg 4.0      time 3m 06s       sec/tick 141.3   sec/kimg 35.33   maintenance 13.5   cpumem 2.33   gpumem 6.14   reserved 7.05   augment 0.002\n",
            "tick 2     kimg 8.0      time 5m 27s       sec/tick 141.4   sec/kimg 35.35   maintenance 0.0    cpumem 2.33   gpumem 6.15   reserved 7.05   augment 0.007\n",
            "tick 3     kimg 12.0     time 7m 49s       sec/tick 141.8   sec/kimg 35.45   maintenance 0.0    cpumem 2.33   gpumem 6.15   reserved 7.05   augment 0.013\n",
            "tick 4     kimg 16.0     time 10m 10s      sec/tick 141.7   sec/kimg 35.43   maintenance 0.0    cpumem 2.33   gpumem 6.15   reserved 7.05   augment 0.016\n",
            "tick 5     kimg 20.0     time 12m 32s      sec/tick 141.7   sec/kimg 35.43   maintenance 0.0    cpumem 2.33   gpumem 6.15   reserved 7.05   augment 0.013\n",
            "tick 6     kimg 24.0     time 14m 54s      sec/tick 141.6   sec/kimg 35.40   maintenance 0.0    cpumem 2.33   gpumem 6.15   reserved 7.05   augment 0.016\n",
            "tick 7     kimg 28.0     time 17m 16s      sec/tick 141.7   sec/kimg 35.42   maintenance 0.0    cpumem 2.33   gpumem 6.15   reserved 7.05   augment 0.019\n",
            "tick 8     kimg 32.0     time 19m 37s      sec/tick 141.6   sec/kimg 35.41   maintenance 0.0    cpumem 2.33   gpumem 6.15   reserved 7.05   augment 0.017\n",
            "tick 9     kimg 36.0     time 21m 59s      sec/tick 141.7   sec/kimg 35.42   maintenance 0.0    cpumem 2.33   gpumem 6.15   reserved 7.05   augment 0.012\n",
            "tick 10    kimg 40.0     time 24m 21s      sec/tick 141.7   sec/kimg 35.42   maintenance 0.0    cpumem 2.33   gpumem 6.15   reserved 7.05   augment 0.007\n",
            "tick 11    kimg 44.0     time 26m 42s      sec/tick 141.4   sec/kimg 35.35   maintenance 0.0    cpumem 2.33   gpumem 6.15   reserved 7.05   augment 0.008\n",
            "tick 12    kimg 48.0     time 29m 03s      sec/tick 141.4   sec/kimg 35.34   maintenance 0.0    cpumem 2.33   gpumem 6.15   reserved 7.05   augment 0.013\n",
            "tick 13    kimg 52.0     time 31m 25s      sec/tick 141.7   sec/kimg 35.42   maintenance 0.0    cpumem 2.33   gpumem 6.15   reserved 7.05   augment 0.014\n",
            "tick 14    kimg 56.0     time 33m 47s      sec/tick 141.9   sec/kimg 35.47   maintenance 0.0    cpumem 2.33   gpumem 6.15   reserved 7.05   augment 0.014\n",
            "tick 15    kimg 60.0     time 36m 09s      sec/tick 142.0   sec/kimg 35.50   maintenance 0.0    cpumem 2.33   gpumem 6.15   reserved 7.05   augment 0.013\n",
            "tick 16    kimg 64.0     time 38m 31s      sec/tick 141.9   sec/kimg 35.47   maintenance 0.0    cpumem 2.33   gpumem 6.15   reserved 7.05   augment 0.009\n",
            "tick 17    kimg 68.0     time 40m 53s      sec/tick 141.7   sec/kimg 35.41   maintenance 0.0    cpumem 2.33   gpumem 6.15   reserved 7.05   augment 0.013\n",
            "tick 18    kimg 72.0     time 43m 15s      sec/tick 142.1   sec/kimg 35.52   maintenance 0.0    cpumem 2.33   gpumem 6.15   reserved 7.05   augment 0.013\n",
            "tick 19    kimg 76.0     time 45m 37s      sec/tick 141.8   sec/kimg 35.46   maintenance 0.0    cpumem 2.33   gpumem 6.15   reserved 7.05   augment 0.007\n",
            "tick 20    kimg 80.0     time 47m 58s      sec/tick 141.6   sec/kimg 35.41   maintenance 0.0    cpumem 2.33   gpumem 6.15   reserved 7.05   augment 0.001\n",
            "tick 21    kimg 84.0     time 50m 20s      sec/tick 141.5   sec/kimg 35.39   maintenance 0.0    cpumem 2.33   gpumem 6.15   reserved 7.05   augment 0.000\n",
            "tick 22    kimg 88.0     time 52m 41s      sec/tick 141.3   sec/kimg 35.33   maintenance 0.0    cpumem 2.33   gpumem 6.15   reserved 7.05   augment 0.000\n",
            "tick 23    kimg 92.0     time 55m 03s      sec/tick 141.6   sec/kimg 35.39   maintenance 0.0    cpumem 2.33   gpumem 6.15   reserved 7.05   augment 0.003\n",
            "tick 24    kimg 96.0     time 57m 24s      sec/tick 141.6   sec/kimg 35.41   maintenance 0.0    cpumem 2.33   gpumem 6.15   reserved 7.05   augment 0.002\n",
            "tick 25    kimg 100.0    time 59m 46s      sec/tick 141.4   sec/kimg 35.35   maintenance 0.0    cpumem 2.33   gpumem 6.15   reserved 7.05   augment 0.000\n",
            "tick 26    kimg 104.0    time 1h 02m 08s   sec/tick 141.9   sec/kimg 35.47   maintenance 0.0    cpumem 2.33   gpumem 6.14   reserved 7.05   augment 0.000\n",
            "tick 27    kimg 108.0    time 1h 04m 29s   sec/tick 141.7   sec/kimg 35.42   maintenance 0.0    cpumem 2.33   gpumem 6.14   reserved 7.05   augment 0.000\n",
            "tick 28    kimg 112.0    time 1h 06m 51s   sec/tick 142.0   sec/kimg 35.50   maintenance 0.0    cpumem 2.33   gpumem 6.14   reserved 7.05   augment 0.000\n",
            "tick 29    kimg 116.0    time 1h 09m 13s   sec/tick 142.0   sec/kimg 35.49   maintenance 0.0    cpumem 2.33   gpumem 6.14   reserved 7.05   augment 0.000\n",
            "tick 30    kimg 120.0    time 1h 11m 35s   sec/tick 141.9   sec/kimg 35.49   maintenance 0.0    cpumem 2.33   gpumem 6.14   reserved 7.05   augment 0.000\n",
            "tick 31    kimg 124.0    time 1h 13m 57s   sec/tick 142.0   sec/kimg 35.49   maintenance 0.0    cpumem 2.33   gpumem 6.14   reserved 7.05   augment 0.000\n",
            "tick 32    kimg 128.0    time 1h 16m 19s   sec/tick 141.9   sec/kimg 35.48   maintenance 0.0    cpumem 2.33   gpumem 6.14   reserved 7.05   augment 0.000\n",
            "tick 33    kimg 132.0    time 1h 18m 41s   sec/tick 141.8   sec/kimg 35.44   maintenance 0.0    cpumem 2.33   gpumem 6.15   reserved 7.05   augment 0.000\n",
            "tick 34    kimg 136.0    time 1h 21m 03s   sec/tick 141.9   sec/kimg 35.47   maintenance 0.0    cpumem 2.33   gpumem 6.14   reserved 7.05   augment 0.000\n",
            "tick 35    kimg 140.0    time 1h 23m 25s   sec/tick 141.9   sec/kimg 35.48   maintenance 0.0    cpumem 2.33   gpumem 6.14   reserved 7.05   augment 0.000\n",
            "tick 36    kimg 144.0    time 1h 25m 47s   sec/tick 141.8   sec/kimg 35.44   maintenance 0.0    cpumem 2.33   gpumem 6.14   reserved 7.05   augment 0.000\n",
            "tick 37    kimg 148.0    time 1h 28m 08s   sec/tick 141.8   sec/kimg 35.46   maintenance 0.0    cpumem 2.33   gpumem 6.14   reserved 7.05   augment 0.000\n",
            "tick 38    kimg 152.0    time 1h 30m 30s   sec/tick 141.6   sec/kimg 35.41   maintenance 0.0    cpumem 2.33   gpumem 6.14   reserved 7.05   augment 0.000\n",
            "tick 39    kimg 156.0    time 1h 32m 52s   sec/tick 141.8   sec/kimg 35.44   maintenance 0.0    cpumem 2.33   gpumem 6.14   reserved 7.05   augment 0.000\n",
            "tick 40    kimg 160.0    time 1h 35m 14s   sec/tick 141.7   sec/kimg 35.43   maintenance 0.0    cpumem 2.33   gpumem 6.14   reserved 7.05   augment 0.000\n",
            "tick 41    kimg 164.0    time 1h 37m 36s   sec/tick 141.9   sec/kimg 35.47   maintenance 0.0    cpumem 2.33   gpumem 6.14   reserved 7.05   augment 0.000\n",
            "tick 42    kimg 168.0    time 1h 39m 57s   sec/tick 141.4   sec/kimg 35.36   maintenance 0.0    cpumem 2.33   gpumem 6.14   reserved 7.05   augment 0.000\n",
            "tick 43    kimg 172.0    time 1h 42m 18s   sec/tick 141.3   sec/kimg 35.32   maintenance 0.0    cpumem 2.33   gpumem 6.14   reserved 7.05   augment 0.000\n",
            "tick 44    kimg 176.0    time 1h 44m 39s   sec/tick 140.8   sec/kimg 35.21   maintenance 0.0    cpumem 2.33   gpumem 6.15   reserved 7.05   augment 0.006\n",
            "tick 45    kimg 180.0    time 1h 47m 00s   sec/tick 141.1   sec/kimg 35.29   maintenance 0.0    cpumem 2.33   gpumem 6.15   reserved 7.05   augment 0.013\n",
            "tick 46    kimg 184.0    time 1h 49m 22s   sec/tick 141.3   sec/kimg 35.33   maintenance 0.0    cpumem 2.33   gpumem 6.15   reserved 7.05   augment 0.021\n",
            "tick 47    kimg 188.0    time 1h 51m 43s   sec/tick 141.3   sec/kimg 35.32   maintenance 0.0    cpumem 2.33   gpumem 6.15   reserved 7.05   augment 0.028\n",
            "tick 48    kimg 192.0    time 1h 54m 04s   sec/tick 141.1   sec/kimg 35.27   maintenance 0.0    cpumem 2.33   gpumem 6.15   reserved 7.05   augment 0.033\n",
            "tick 49    kimg 196.0    time 1h 56m 25s   sec/tick 141.2   sec/kimg 35.31   maintenance 0.0    cpumem 2.33   gpumem 6.15   reserved 7.05   augment 0.035\n",
            "tick 50    kimg 200.0    time 1h 58m 47s   sec/tick 141.4   sec/kimg 35.35   maintenance 0.0    cpumem 2.33   gpumem 6.15   reserved 7.05   augment 0.037\n",
            "tick 51    kimg 204.0    time 2h 01m 19s   sec/tick 141.6   sec/kimg 35.41   maintenance 11.0   cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.034\n",
            "tick 52    kimg 208.0    time 2h 03m 41s   sec/tick 141.7   sec/kimg 35.41   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.034\n",
            "tick 53    kimg 212.0    time 2h 06m 03s   sec/tick 141.6   sec/kimg 35.40   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.030\n",
            "tick 54    kimg 216.0    time 2h 08m 24s   sec/tick 141.4   sec/kimg 35.35   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.026\n",
            "tick 55    kimg 220.0    time 2h 10m 46s   sec/tick 141.6   sec/kimg 35.39   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.022\n",
            "tick 56    kimg 224.0    time 2h 13m 07s   sec/tick 141.7   sec/kimg 35.43   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.018\n",
            "tick 57    kimg 228.0    time 2h 15m 29s   sec/tick 141.7   sec/kimg 35.42   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.015\n",
            "tick 58    kimg 232.0    time 2h 17m 51s   sec/tick 142.0   sec/kimg 35.49   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.012\n",
            "tick 59    kimg 236.0    time 2h 20m 13s   sec/tick 141.5   sec/kimg 35.39   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.011\n",
            "tick 60    kimg 240.0    time 2h 22m 34s   sec/tick 141.8   sec/kimg 35.46   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.008\n",
            "tick 61    kimg 244.0    time 2h 24m 56s   sec/tick 141.8   sec/kimg 35.44   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.008\n",
            "tick 62    kimg 248.0    time 2h 27m 18s   sec/tick 141.8   sec/kimg 35.45   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.006\n",
            "tick 63    kimg 252.0    time 2h 29m 40s   sec/tick 141.6   sec/kimg 35.40   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.007\n",
            "tick 64    kimg 256.0    time 2h 32m 01s   sec/tick 141.7   sec/kimg 35.42   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.008\n",
            "tick 65    kimg 260.0    time 2h 34m 23s   sec/tick 141.7   sec/kimg 35.42   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.010\n",
            "tick 66    kimg 264.0    time 2h 36m 45s   sec/tick 141.7   sec/kimg 35.43   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.011\n",
            "tick 67    kimg 268.0    time 2h 39m 06s   sec/tick 141.6   sec/kimg 35.40   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.012\n",
            "tick 68    kimg 272.0    time 2h 41m 28s   sec/tick 141.6   sec/kimg 35.39   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.013\n",
            "tick 69    kimg 276.0    time 2h 43m 50s   sec/tick 141.5   sec/kimg 35.39   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.015\n",
            "tick 70    kimg 280.0    time 2h 46m 11s   sec/tick 141.3   sec/kimg 35.33   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.018\n",
            "tick 71    kimg 284.0    time 2h 48m 33s   sec/tick 141.6   sec/kimg 35.40   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.023\n",
            "tick 72    kimg 288.0    time 2h 50m 54s   sec/tick 141.6   sec/kimg 35.39   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.026\n",
            "tick 73    kimg 292.0    time 2h 53m 16s   sec/tick 141.6   sec/kimg 35.41   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.029\n",
            "tick 74    kimg 296.0    time 2h 55m 37s   sec/tick 141.5   sec/kimg 35.38   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.031\n",
            "tick 75    kimg 300.0    time 2h 57m 59s   sec/tick 141.3   sec/kimg 35.32   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.032\n",
            "tick 76    kimg 304.0    time 3h 00m 20s   sec/tick 141.6   sec/kimg 35.40   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.035\n",
            "tick 77    kimg 308.0    time 3h 02m 42s   sec/tick 141.8   sec/kimg 35.44   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.038\n",
            "tick 78    kimg 312.0    time 3h 05m 04s   sec/tick 141.6   sec/kimg 35.41   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.038\n",
            "tick 79    kimg 316.0    time 3h 07m 25s   sec/tick 141.8   sec/kimg 35.44   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.040\n",
            "tick 80    kimg 320.0    time 3h 09m 48s   sec/tick 142.2   sec/kimg 35.55   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.041\n",
            "tick 81    kimg 324.0    time 3h 12m 10s   sec/tick 142.1   sec/kimg 35.53   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.040\n",
            "tick 82    kimg 328.0    time 3h 14m 32s   sec/tick 142.3   sec/kimg 35.56   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.041\n",
            "tick 83    kimg 332.0    time 3h 16m 54s   sec/tick 142.3   sec/kimg 35.59   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.042\n",
            "tick 84    kimg 336.0    time 3h 19m 17s   sec/tick 142.2   sec/kimg 35.54   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.043\n",
            "tick 85    kimg 340.0    time 3h 21m 39s   sec/tick 142.1   sec/kimg 35.53   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.044\n",
            "tick 86    kimg 344.0    time 3h 24m 01s   sec/tick 142.1   sec/kimg 35.52   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.044\n",
            "tick 87    kimg 348.0    time 3h 26m 23s   sec/tick 142.2   sec/kimg 35.54   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.046\n",
            "tick 88    kimg 352.0    time 3h 28m 45s   sec/tick 141.8   sec/kimg 35.46   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.048\n",
            "tick 89    kimg 356.0    time 3h 31m 07s   sec/tick 141.8   sec/kimg 35.46   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.050\n",
            "tick 90    kimg 360.0    time 3h 33m 29s   sec/tick 141.9   sec/kimg 35.48   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.052\n",
            "tick 91    kimg 364.0    time 3h 35m 50s   sec/tick 141.8   sec/kimg 35.46   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.052\n",
            "tick 92    kimg 368.0    time 3h 38m 13s   sec/tick 142.2   sec/kimg 35.55   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.052\n",
            "tick 93    kimg 372.0    time 3h 40m 35s   sec/tick 142.0   sec/kimg 35.51   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.054\n",
            "tick 94    kimg 376.0    time 3h 42m 57s   sec/tick 142.2   sec/kimg 35.55   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.056\n",
            "tick 95    kimg 380.0    time 3h 45m 19s   sec/tick 142.2   sec/kimg 35.55   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.054\n",
            "tick 96    kimg 384.0    time 3h 47m 42s   sec/tick 142.3   sec/kimg 35.58   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.054\n",
            "tick 97    kimg 388.0    time 3h 50m 04s   sec/tick 142.0   sec/kimg 35.50   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.055\n",
            "tick 98    kimg 392.0    time 3h 52m 26s   sec/tick 142.2   sec/kimg 35.55   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.056\n",
            "tick 99    kimg 396.0    time 3h 54m 48s   sec/tick 142.1   sec/kimg 35.53   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.056\n",
            "tick 100   kimg 400.0    time 3h 57m 10s   sec/tick 142.1   sec/kimg 35.52   maintenance 0.0    cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.055\n",
            "tick 101   kimg 404.0    time 3h 59m 48s   sec/tick 142.6   sec/kimg 35.65   maintenance 15.7   cpumem 2.28   gpumem 6.15   reserved 7.05   augment 0.056\n"
          ]
        }
      ],
      "source": [
        "!python /content/stylegan3/train.py --outdir=/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/experiments/training-runs --cfg=stylegan3-t --data=/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/dataset/portraits.zip \\\n",
        "    --gpus=1 --batch=32 --batch-gpu=16 --metrics=none --gamma=6.6 --mirror=1 --kimg=500 --snap=50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gq1g-JQ8oLyV",
        "outputId": "f2f51ffd-4e7e-4a47-deb4-ad83b776c321"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan3.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"magnitude_ema_beta\": 0.9988915792636801\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan2.Discriminator\",\n",
            "    \"block_kwargs\": {\n",
            "      \"freeze_layers\": 0\n",
            "    },\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.0025\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 6.6,\n",
            "    \"blur_init_sigma\": 0\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"prefetch_factor\": 2,\n",
            "    \"num_workers\": 3\n",
            "  },\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/dataset/portraits.zip\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 560,\n",
            "    \"xflip\": true,\n",
            "    \"resolution\": 64,\n",
            "    \"random_seed\": 0\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"batch_size\": 32,\n",
            "  \"batch_gpu\": 16,\n",
            "  \"metrics\": [],\n",
            "  \"total_kimg\": 96,\n",
            "  \"kimg_per_tick\": 4,\n",
            "  \"image_snapshot_ticks\": 10,\n",
            "  \"network_snapshot_ticks\": 10,\n",
            "  \"random_seed\": 0,\n",
            "  \"ema_kimg\": 10.0,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1,\n",
            "    \"brightness\": 1,\n",
            "    \"contrast\": 1,\n",
            "    \"lumaflip\": 1,\n",
            "    \"hue\": 1,\n",
            "    \"saturation\": 1\n",
            "  },\n",
            "  \"ada_target\": 0.6,\n",
            "  \"resume_pkl\": \"/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/experiments/training-runs/00000-stylegan3-t-portraits-gpus1-batch32-gamma6.6/network-snapshot-000500.pkl\",\n",
            "  \"ada_kimg\": 100,\n",
            "  \"ema_rampup\": null,\n",
            "  \"run_dir\": \"/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/experiments/training-runs/00002-stylegan3-t-portraits-gpus1-batch32-gamma6.6\"\n",
            "}\n",
            "\n",
            "Output directory:    /content/drive/MyDrive/GANsNFTs/StyleGAN/gan/experiments/training-runs/00002-stylegan3-t-portraits-gpus1-batch32-gamma6.6\n",
            "Number of GPUs:      1\n",
            "Batch size:          32 images\n",
            "Training duration:   96 kimg\n",
            "Dataset path:        /content/drive/MyDrive/GANsNFTs/StyleGAN/gan/dataset/portraits.zip\n",
            "Dataset size:        560 images\n",
            "Dataset resolution:  64\n",
            "Dataset labels:      False\n",
            "Dataset x-flips:     True\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/sampler.py:64: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
            "  warnings.warn(\"`data_source` argument is not used and will be removed in 2.2.0.\"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "Num images:  1120\n",
            "Image shape: [3, 64, 64]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Resuming from \"/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/experiments/training-runs/00000-stylegan3-t-portraits-gpus1-batch32-gamma6.6/network-snapshot-000500.pkl\"\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "\n",
            "Generator                    Parameters  Buffers  Output shape       Datatype\n",
            "---                          ---         ---      ---                ---     \n",
            "mapping.fc0                  262656      -        [16, 512]          float32 \n",
            "mapping.fc1                  262656      -        [16, 512]          float32 \n",
            "mapping                      -           512      [16, 16, 512]      float32 \n",
            "synthesis.input.affine       2052        -        [16, 4]            float32 \n",
            "synthesis.input              262144      1545     [16, 512, 36, 36]  float32 \n",
            "synthesis.L0_36_512.affine   262656      -        [16, 512]          float32 \n",
            "synthesis.L0_36_512          2359808     25       [16, 512, 36, 36]  float16 \n",
            "synthesis.L1_36_512.affine   262656      -        [16, 512]          float32 \n",
            "synthesis.L1_36_512          2359808     25       [16, 512, 36, 36]  float16 \n",
            "synthesis.L2_36_512.affine   262656      -        [16, 512]          float32 \n",
            "synthesis.L2_36_512          2359808     25       [16, 512, 36, 36]  float16 \n",
            "synthesis.L3_36_512.affine   262656      -        [16, 512]          float32 \n",
            "synthesis.L3_36_512          2359808     25       [16, 512, 36, 36]  float16 \n",
            "synthesis.L4_52_512.affine   262656      -        [16, 512]          float32 \n",
            "synthesis.L4_52_512          2359808     37       [16, 512, 52, 52]  float16 \n",
            "synthesis.L5_52_512.affine   262656      -        [16, 512]          float32 \n",
            "synthesis.L5_52_512          2359808     25       [16, 512, 52, 52]  float16 \n",
            "synthesis.L6_52_512.affine   262656      -        [16, 512]          float32 \n",
            "synthesis.L6_52_512          2359808     25       [16, 512, 52, 52]  float16 \n",
            "synthesis.L7_52_512.affine   262656      -        [16, 512]          float32 \n",
            "synthesis.L7_52_512          2359808     25       [16, 512, 52, 52]  float16 \n",
            "synthesis.L8_84_512.affine   262656      -        [16, 512]          float32 \n",
            "synthesis.L8_84_512          2359808     37       [16, 512, 84, 84]  float16 \n",
            "synthesis.L9_84_512.affine   262656      -        [16, 512]          float32 \n",
            "synthesis.L9_84_512          2359808     25       [16, 512, 84, 84]  float16 \n",
            "synthesis.L10_84_512.affine  262656      -        [16, 512]          float32 \n",
            "synthesis.L10_84_512         2359808     25       [16, 512, 84, 84]  float16 \n",
            "synthesis.L11_84_512.affine  262656      -        [16, 512]          float32 \n",
            "synthesis.L11_84_512         2359808     25       [16, 512, 84, 84]  float16 \n",
            "synthesis.L12_84_512.affine  262656      -        [16, 512]          float32 \n",
            "synthesis.L12_84_512         2359808     25       [16, 512, 84, 84]  float16 \n",
            "synthesis.L13_64_512.affine  262656      -        [16, 512]          float32 \n",
            "synthesis.L13_64_512         2359808     25       [16, 512, 64, 64]  float16 \n",
            "synthesis.L14_64_3.affine    262656      -        [16, 512]          float32 \n",
            "synthesis.L14_64_3           1539        1        [16, 3, 64, 64]    float16 \n",
            "synthesis                    -           -        [16, 3, 64, 64]    float32 \n",
            "---                          ---         ---      ---                ---     \n",
            "Total                        37768199    2432     -                  -       \n",
            "\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape       Datatype\n",
            "---            ---         ---      ---                ---     \n",
            "b64.fromrgb    2048        16       [16, 512, 64, 64]  float16 \n",
            "b64.skip       262144      16       [16, 512, 32, 32]  float16 \n",
            "b64.conv0      2359808     16       [16, 512, 64, 64]  float16 \n",
            "b64.conv1      2359808     16       [16, 512, 32, 32]  float16 \n",
            "b64            -           16       [16, 512, 32, 32]  float16 \n",
            "b32.skip       262144      16       [16, 512, 16, 16]  float16 \n",
            "b32.conv0      2359808     16       [16, 512, 32, 32]  float16 \n",
            "b32.conv1      2359808     16       [16, 512, 16, 16]  float16 \n",
            "b32            -           16       [16, 512, 16, 16]  float16 \n",
            "b16.skip       262144      16       [16, 512, 8, 8]    float16 \n",
            "b16.conv0      2359808     16       [16, 512, 16, 16]  float16 \n",
            "b16.conv1      2359808     16       [16, 512, 8, 8]    float16 \n",
            "b16            -           16       [16, 512, 8, 8]    float16 \n",
            "b8.skip        262144      16       [16, 512, 4, 4]    float16 \n",
            "b8.conv0       2359808     16       [16, 512, 8, 8]    float16 \n",
            "b8.conv1       2359808     16       [16, 512, 4, 4]    float16 \n",
            "b8             -           16       [16, 512, 4, 4]    float16 \n",
            "b4.mbstd       -           -        [16, 513, 4, 4]    float32 \n",
            "b4.conv        2364416     16       [16, 512, 4, 4]    float32 \n",
            "b4.fc          4194816     -        [16, 512]          float32 \n",
            "b4.out         513         -        [16, 1]            float32 \n",
            "---            ---         ---      ---                ---     \n",
            "Total          26488833    288      -                  -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "2024-04-08 07:50:25.277320: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-08 07:50:25.277378: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-08 07:50:25.278711: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-08 07:50:26.478087: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Training for 96 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      time 32s          sec/tick 5.7     sec/kimg 176.67  maintenance 26.5   cpumem 2.57   gpumem 13.70  reserved 14.66  augment 0.000\n",
            "tick 1     kimg 4.0      time 3m 06s       sec/tick 143.4   sec/kimg 35.85   maintenance 10.7   cpumem 2.81   gpumem 6.15   reserved 7.07   augment 0.040\n",
            "tick 2     kimg 8.0      time 5m 30s       sec/tick 143.7   sec/kimg 35.92   maintenance 0.0    cpumem 2.81   gpumem 6.15   reserved 7.07   augment 0.067\n",
            "tick 3     kimg 12.0     time 7m 53s       sec/tick 143.4   sec/kimg 35.84   maintenance 0.0    cpumem 2.81   gpumem 6.15   reserved 7.07   augment 0.069\n",
            "tick 4     kimg 16.0     time 10m 17s      sec/tick 143.2   sec/kimg 35.81   maintenance 0.0    cpumem 2.81   gpumem 6.15   reserved 7.07   augment 0.064\n",
            "tick 5     kimg 20.0     time 12m 40s      sec/tick 143.5   sec/kimg 35.88   maintenance 0.0    cpumem 2.81   gpumem 6.15   reserved 7.07   augment 0.068\n",
            "tick 6     kimg 24.0     time 15m 03s      sec/tick 143.2   sec/kimg 35.79   maintenance 0.0    cpumem 2.81   gpumem 6.15   reserved 7.07   augment 0.072\n",
            "tick 7     kimg 28.0     time 17m 27s      sec/tick 143.3   sec/kimg 35.83   maintenance 0.0    cpumem 2.81   gpumem 6.15   reserved 7.07   augment 0.076\n",
            "tick 8     kimg 32.0     time 19m 50s      sec/tick 143.3   sec/kimg 35.83   maintenance 0.0    cpumem 2.81   gpumem 6.15   reserved 7.07   augment 0.070\n",
            "tick 9     kimg 36.0     time 22m 14s      sec/tick 143.6   sec/kimg 35.89   maintenance 0.0    cpumem 2.81   gpumem 6.15   reserved 7.07   augment 0.070\n",
            "tick 10    kimg 40.0     time 24m 37s      sec/tick 143.4   sec/kimg 35.86   maintenance 0.0    cpumem 2.81   gpumem 6.15   reserved 7.07   augment 0.070\n",
            "tick 11    kimg 44.0     time 27m 12s      sec/tick 143.6   sec/kimg 35.90   maintenance 11.0   cpumem 2.77   gpumem 6.15   reserved 7.07   augment 0.064\n",
            "tick 12    kimg 48.0     time 29m 35s      sec/tick 143.5   sec/kimg 35.88   maintenance 0.0    cpumem 2.77   gpumem 6.15   reserved 7.07   augment 0.068\n",
            "tick 13    kimg 52.0     time 31m 58s      sec/tick 143.3   sec/kimg 35.83   maintenance 0.0    cpumem 2.77   gpumem 6.15   reserved 7.07   augment 0.061\n",
            "tick 14    kimg 56.0     time 34m 22s      sec/tick 143.4   sec/kimg 35.85   maintenance 0.0    cpumem 2.77   gpumem 6.15   reserved 7.07   augment 0.065\n",
            "tick 15    kimg 60.0     time 36m 45s      sec/tick 143.5   sec/kimg 35.88   maintenance 0.0    cpumem 2.77   gpumem 6.15   reserved 7.07   augment 0.070\n",
            "tick 16    kimg 64.0     time 39m 09s      sec/tick 143.5   sec/kimg 35.87   maintenance 0.0    cpumem 2.77   gpumem 6.15   reserved 7.07   augment 0.065\n",
            "tick 17    kimg 68.0     time 41m 32s      sec/tick 143.0   sec/kimg 35.75   maintenance 0.0    cpumem 2.77   gpumem 6.15   reserved 7.07   augment 0.061\n",
            "tick 18    kimg 72.0     time 43m 55s      sec/tick 143.4   sec/kimg 35.84   maintenance 0.0    cpumem 2.77   gpumem 6.15   reserved 7.07   augment 0.064\n",
            "tick 19    kimg 76.0     time 46m 19s      sec/tick 143.4   sec/kimg 35.85   maintenance 0.0    cpumem 2.77   gpumem 6.15   reserved 7.07   augment 0.064\n",
            "tick 20    kimg 80.0     time 48m 42s      sec/tick 143.2   sec/kimg 35.80   maintenance 0.0    cpumem 2.77   gpumem 6.15   reserved 7.07   augment 0.065\n",
            "tick 21    kimg 84.0     time 51m 19s      sec/tick 143.5   sec/kimg 35.87   maintenance 14.0   cpumem 2.77   gpumem 6.15   reserved 7.07   augment 0.070\n",
            "tick 22    kimg 88.0     time 53m 43s      sec/tick 143.4   sec/kimg 35.86   maintenance 0.0    cpumem 2.77   gpumem 6.15   reserved 7.07   augment 0.072\n",
            "tick 23    kimg 92.0     time 56m 06s      sec/tick 143.4   sec/kimg 35.86   maintenance 0.0    cpumem 2.77   gpumem 6.15   reserved 7.07   augment 0.069\n",
            "tick 24    kimg 96.0     time 58m 29s      sec/tick 142.4   sec/kimg 35.88   maintenance 0.0    cpumem 2.77   gpumem 6.15   reserved 7.07   augment 0.073\n",
            "\n",
            "Exiting...\n"
          ]
        }
      ],
      "source": [
        "!python /content/stylegan3/train.py --outdir=/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/experiments/training-runs \\\n",
        "    --cfg=stylegan3-t --data=/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/dataset/portraits.zip \\\n",
        "    --gpus=1 --batch=32 --batch-gpu=16 --metrics=none --gamma=6.6 --mirror=1 --kimg=96 --snap=10 \\\n",
        "    --resume=/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/experiments/training-runs/00000-stylegan3-t-portraits-gpus1-batch32-gamma6.6/network-snapshot-000500.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-ZZJdGOoeeE",
        "outputId": "7cd2f94a-cb69-4d26-caea-c4d2b21ad152"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python3: can't open file '/content/stylegan3/gen_images.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!python /content/stylegan3/gen_images.py --outdir=/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/experiments/out --trunc=1 --seeds=84,264,296,850 \\\n",
        "    --network=/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/experiments/portraits_256x256/training-runs/00000-stylegan3-t-portraits_256x256-gpus1-batch32-gamma6.6/network-snapshot-000040.pkl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwQrxXJ2DyYT"
      },
      "source": [
        "## **Portraits 256x256**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Etp6E-yFg-F_"
      },
      "source": [
        "###Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuT8HsoIwE2f",
        "outputId": "870a7c45-3340-4d43-e052-0920e03f728b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'stylegan3'...\n",
            "remote: Enumerating objects: 212, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 212 (delta 0), reused 1 (delta 0), pack-reused 207\u001b[K\n",
            "Receiving objects: 100% (212/212), 4.16 MiB | 32.06 MiB/s, done.\n",
            "Resolving deltas: 100% (101/101), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/NVlabs/stylegan3.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVLyXPWywGHQ",
        "outputId": "02150b5b-ef9b-45cb-e695-e7edbb1fb2ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ninja\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.11.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install ninja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYp6LgXoGFtl",
        "outputId": "7c1ed7d7-e39f-43e6-b3e0-30021c681a9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/images/portraits/r256x256\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/GANsNFTs/StyleGAN/gan/images/portraits/r256x256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvwa33oOFO6N",
        "outputId": "f128d756-cf4f-4628-f702-c0be8a823606"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100% 14965/14965 [04:26<00:00, 56.10it/s]\n"
          ]
        }
      ],
      "source": [
        "!python /content/stylegan3/dataset_tool.py --source=/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/images/portraits/r256x256 --dest=/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/dataset/portraits_256x256.zip --resolution='256x256'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPtMkYLiD2GW",
        "outputId": "b68bd0c6-fd8e-460b-c937-0191fe443f3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan3.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"magnitude_ema_beta\": 0.9988915792636801\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan2.Discriminator\",\n",
            "    \"block_kwargs\": {\n",
            "      \"freeze_layers\": 0\n",
            "    },\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.0025\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 6.6\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"prefetch_factor\": 2,\n",
            "    \"num_workers\": 3\n",
            "  },\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/dataset/portraits_256x256.zip\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 14965,\n",
            "    \"xflip\": true,\n",
            "    \"resolution\": 256,\n",
            "    \"random_seed\": 0\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"batch_size\": 32,\n",
            "  \"batch_gpu\": 16,\n",
            "  \"metrics\": [\n",
            "    \"fid50k_full\"\n",
            "  ],\n",
            "  \"total_kimg\": 500,\n",
            "  \"kimg_per_tick\": 4,\n",
            "  \"image_snapshot_ticks\": 10,\n",
            "  \"network_snapshot_ticks\": 10,\n",
            "  \"random_seed\": 0,\n",
            "  \"ema_kimg\": 10.0,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1,\n",
            "    \"brightness\": 1,\n",
            "    \"contrast\": 1,\n",
            "    \"lumaflip\": 1,\n",
            "    \"hue\": 1,\n",
            "    \"saturation\": 1\n",
            "  },\n",
            "  \"ada_target\": 0.6,\n",
            "  \"run_dir\": \"/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/experiments/portraits_256x256/training-runs/00000-stylegan3-t-portraits_256x256-gpus1-batch32-gamma6.6\"\n",
            "}\n",
            "\n",
            "Output directory:    /content/drive/MyDrive/GANsNFTs/StyleGAN/gan/experiments/portraits_256x256/training-runs/00000-stylegan3-t-portraits_256x256-gpus1-batch32-gamma6.6\n",
            "Number of GPUs:      1\n",
            "Batch size:          32 images\n",
            "Training duration:   500 kimg\n",
            "Dataset path:        /content/drive/MyDrive/GANsNFTs/StyleGAN/gan/dataset/portraits_256x256.zip\n",
            "Dataset size:        14965 images\n",
            "Dataset resolution:  256\n",
            "Dataset labels:      False\n",
            "Dataset x-flips:     True\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/sampler.py:64: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
            "  warnings.warn(\"`data_source` argument is not used and will be removed in 2.2.0.\"\n",
            "\n",
            "Num images:  29930\n",
            "Image shape: [3, 256, 256]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "\n",
            "Generator                     Parameters  Buffers  Output shape         Datatype\n",
            "---                           ---         ---      ---                  ---     \n",
            "mapping.fc0                   262656      -        [16, 512]            float32 \n",
            "mapping.fc1                   262656      -        [16, 512]            float32 \n",
            "mapping                       -           512      [16, 16, 512]        float32 \n",
            "synthesis.input.affine        2052        -        [16, 4]              float32 \n",
            "synthesis.input               262144      1545     [16, 512, 36, 36]    float32 \n",
            "synthesis.L0_36_512.affine    262656      -        [16, 512]            float32 \n",
            "synthesis.L0_36_512           2359808     25       [16, 512, 36, 36]    float32 \n",
            "synthesis.L1_36_512.affine    262656      -        [16, 512]            float32 \n",
            "synthesis.L1_36_512           2359808     25       [16, 512, 36, 36]    float32 \n",
            "synthesis.L2_36_512.affine    262656      -        [16, 512]            float32 \n",
            "synthesis.L2_36_512           2359808     25       [16, 512, 36, 36]    float32 \n",
            "synthesis.L3_52_512.affine    262656      -        [16, 512]            float32 \n",
            "synthesis.L3_52_512           2359808     37       [16, 512, 52, 52]    float16 \n",
            "synthesis.L4_52_512.affine    262656      -        [16, 512]            float32 \n",
            "synthesis.L4_52_512           2359808     25       [16, 512, 52, 52]    float16 \n",
            "synthesis.L5_84_512.affine    262656      -        [16, 512]            float32 \n",
            "synthesis.L5_84_512           2359808     37       [16, 512, 84, 84]    float16 \n",
            "synthesis.L6_84_512.affine    262656      -        [16, 512]            float32 \n",
            "synthesis.L6_84_512           2359808     25       [16, 512, 84, 84]    float16 \n",
            "synthesis.L7_148_512.affine   262656      -        [16, 512]            float32 \n",
            "synthesis.L7_148_512          2359808     37       [16, 512, 148, 148]  float16 \n",
            "synthesis.L8_148_512.affine   262656      -        [16, 512]            float32 \n",
            "synthesis.L8_148_512          2359808     25       [16, 512, 148, 148]  float16 \n",
            "synthesis.L9_148_362.affine   262656      -        [16, 512]            float32 \n",
            "synthesis.L9_148_362          1668458     25       [16, 362, 148, 148]  float16 \n",
            "synthesis.L10_276_256.affine  185706      -        [16, 362]            float32 \n",
            "synthesis.L10_276_256         834304      37       [16, 256, 276, 276]  float16 \n",
            "synthesis.L11_276_181.affine  131328      -        [16, 256]            float32 \n",
            "synthesis.L11_276_181         417205      25       [16, 181, 276, 276]  float16 \n",
            "synthesis.L12_276_128.affine  92853       -        [16, 181]            float32 \n",
            "synthesis.L12_276_128         208640      25       [16, 128, 276, 276]  float16 \n",
            "synthesis.L13_256_128.affine  65664       -        [16, 128]            float32 \n",
            "synthesis.L13_256_128         147584      25       [16, 128, 256, 256]  float16 \n",
            "synthesis.L14_256_3.affine    65664       -        [16, 128]            float32 \n",
            "synthesis.L14_256_3           387         1        [16, 3, 256, 256]    float16 \n",
            "synthesis                     -           -        [16, 3, 256, 256]    float32 \n",
            "---                           ---         ---      ---                  ---     \n",
            "Total                         28472133    2456     -                    -       \n",
            "\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape         Datatype\n",
            "---            ---         ---      ---                  ---     \n",
            "b256.fromrgb   512         16       [16, 128, 256, 256]  float16 \n",
            "b256.skip      32768       16       [16, 256, 128, 128]  float16 \n",
            "b256.conv0     147584      16       [16, 128, 256, 256]  float16 \n",
            "b256.conv1     295168      16       [16, 256, 128, 128]  float16 \n",
            "b256           -           16       [16, 256, 128, 128]  float16 \n",
            "b128.skip      131072      16       [16, 512, 64, 64]    float16 \n",
            "b128.conv0     590080      16       [16, 256, 128, 128]  float16 \n",
            "b128.conv1     1180160     16       [16, 512, 64, 64]    float16 \n",
            "b128           -           16       [16, 512, 64, 64]    float16 \n",
            "b64.skip       262144      16       [16, 512, 32, 32]    float16 \n",
            "b64.conv0      2359808     16       [16, 512, 64, 64]    float16 \n",
            "b64.conv1      2359808     16       [16, 512, 32, 32]    float16 \n",
            "b64            -           16       [16, 512, 32, 32]    float16 \n",
            "b32.skip       262144      16       [16, 512, 16, 16]    float16 \n",
            "b32.conv0      2359808     16       [16, 512, 32, 32]    float16 \n",
            "b32.conv1      2359808     16       [16, 512, 16, 16]    float16 \n",
            "b32            -           16       [16, 512, 16, 16]    float16 \n",
            "b16.skip       262144      16       [16, 512, 8, 8]      float32 \n",
            "b16.conv0      2359808     16       [16, 512, 16, 16]    float32 \n",
            "b16.conv1      2359808     16       [16, 512, 8, 8]      float32 \n",
            "b16            -           16       [16, 512, 8, 8]      float32 \n",
            "b8.skip        262144      16       [16, 512, 4, 4]      float32 \n",
            "b8.conv0       2359808     16       [16, 512, 8, 8]      float32 \n",
            "b8.conv1       2359808     16       [16, 512, 4, 4]      float32 \n",
            "b8             -           16       [16, 512, 4, 4]      float32 \n",
            "b4.mbstd       -           -        [16, 513, 4, 4]      float32 \n",
            "b4.conv        2364416     16       [16, 512, 4, 4]      float32 \n",
            "b4.fc          4194816     -        [16, 512]            float32 \n",
            "b4.out         513         -        [16, 1]              float32 \n",
            "---            ---         ---      ---                  ---     \n",
            "Total          28864129    416      -                    -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "2024-04-08 21:28:29.805776: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-08 21:28:29.805836: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-08 21:28:29.807773: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-08 21:28:30.850635: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Training for 500 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      time 3m 14s       sec/tick 31.2    sec/kimg 975.08  maintenance 163.2  cpumem 2.83   gpumem 37.84  reserved 38.34  augment 0.000\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 496.92465934892994}, \"metric\": \"fid50k_full\", \"total_time\": 468.8378200531006, \"total_time_str\": \"7m 49s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000000.pkl\", \"timestamp\": 1712612225.6307986}\n",
            "tick 1     kimg 4.0      time 13m 54s      sec/tick 156.8   sec/kimg 39.21   maintenance 482.7  cpumem 3.45   gpumem 34.39  reserved 34.95  augment 0.001\n",
            "tick 2     kimg 8.0      time 16m 31s      sec/tick 157.3   sec/kimg 39.33   maintenance 0.0    cpumem 3.45   gpumem 10.15  reserved 15.60  augment 0.008\n",
            "tick 3     kimg 12.0     time 19m 09s      sec/tick 157.4   sec/kimg 39.35   maintenance 0.0    cpumem 3.45   gpumem 10.15  reserved 15.60  augment 0.012\n",
            "tick 4     kimg 16.0     time 21m 46s      sec/tick 157.4   sec/kimg 39.34   maintenance 0.0    cpumem 3.45   gpumem 10.15  reserved 15.60  augment 0.013\n",
            "tick 5     kimg 20.0     time 24m 23s      sec/tick 157.4   sec/kimg 39.34   maintenance 0.0    cpumem 3.45   gpumem 10.15  reserved 15.60  augment 0.014\n",
            "tick 6     kimg 24.0     time 27m 00s      sec/tick 157.0   sec/kimg 39.25   maintenance 0.0    cpumem 3.45   gpumem 10.16  reserved 15.60  augment 0.011\n",
            "tick 7     kimg 28.0     time 29m 38s      sec/tick 157.2   sec/kimg 39.29   maintenance 0.0    cpumem 3.45   gpumem 10.15  reserved 15.60  augment 0.006\n",
            "tick 8     kimg 32.0     time 32m 15s      sec/tick 156.9   sec/kimg 39.24   maintenance 0.0    cpumem 3.45   gpumem 10.15  reserved 15.60  augment 0.003\n",
            "tick 9     kimg 36.0     time 34m 52s      sec/tick 157.0   sec/kimg 39.24   maintenance 0.0    cpumem 3.45   gpumem 10.12  reserved 15.60  augment 0.000\n",
            "tick 10    kimg 40.0     time 37m 29s      sec/tick 157.1   sec/kimg 39.27   maintenance 0.0    cpumem 3.45   gpumem 10.15  reserved 15.60  augment 0.003\n",
            "Evaluating metrics...\n"
          ]
        }
      ],
      "source": [
        "!python /content/stylegan3/train.py --outdir=/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/experiments/portraits_256x256/training-runs --cfg=stylegan3-t --data=/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/dataset/portraits_256x256.zip \\\n",
        "    --gpus=1 --batch=32 --batch-gpu=16 --metrics=fid50k_full --gamma=6.6 --mirror=1 --kimg=500 --snap=10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzVHaWP1xe6H",
        "outputId": "de753bbf-a13f-44a0-e96b-582b1de20fa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan3.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"magnitude_ema_beta\": 0.9988915792636801\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan2.Discriminator\",\n",
            "    \"block_kwargs\": {\n",
            "      \"freeze_layers\": 0\n",
            "    },\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.0025\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 6.6,\n",
            "    \"blur_init_sigma\": 0\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"prefetch_factor\": 2,\n",
            "    \"num_workers\": 3\n",
            "  },\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/dataset/portraits_256x256.zip\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 14965,\n",
            "    \"xflip\": true,\n",
            "    \"resolution\": 256,\n",
            "    \"random_seed\": 0\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"batch_size\": 32,\n",
            "  \"batch_gpu\": 16,\n",
            "  \"metrics\": [\n",
            "    \"fid50k_full\"\n",
            "  ],\n",
            "  \"total_kimg\": 500,\n",
            "  \"kimg_per_tick\": 4,\n",
            "  \"image_snapshot_ticks\": 10,\n",
            "  \"network_snapshot_ticks\": 10,\n",
            "  \"random_seed\": 0,\n",
            "  \"ema_kimg\": 10.0,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1,\n",
            "    \"brightness\": 1,\n",
            "    \"contrast\": 1,\n",
            "    \"lumaflip\": 1,\n",
            "    \"hue\": 1,\n",
            "    \"saturation\": 1\n",
            "  },\n",
            "  \"ada_target\": 0.6,\n",
            "  \"resume_pkl\": \"/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/experiments/portraits_256x256/training-runs/00000-stylegan3-t-portraits_256x256-gpus1-batch32-gamma6.6/network-snapshot-000040.pkl\",\n",
            "  \"ada_kimg\": 100,\n",
            "  \"ema_rampup\": null,\n",
            "  \"run_dir\": \"/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/experiments/portraits_256x256/training-runs/00002-stylegan3-t-portraits_256x256-gpus1-batch32-gamma6.6\"\n",
            "}\n",
            "\n",
            "Output directory:    /content/drive/MyDrive/GANsNFTs/StyleGAN/gan/experiments/portraits_256x256/training-runs/00002-stylegan3-t-portraits_256x256-gpus1-batch32-gamma6.6\n",
            "Number of GPUs:      1\n",
            "Batch size:          32 images\n",
            "Training duration:   500 kimg\n",
            "Dataset path:        /content/drive/MyDrive/GANsNFTs/StyleGAN/gan/dataset/portraits_256x256.zip\n",
            "Dataset size:        14965 images\n",
            "Dataset resolution:  256\n",
            "Dataset labels:      False\n",
            "Dataset x-flips:     True\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/sampler.py:64: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
            "  warnings.warn(\"`data_source` argument is not used and will be removed in 2.2.0.\"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "Num images:  29930\n",
            "Image shape: [3, 256, 256]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Resuming from \"/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/experiments/portraits_256x256/training-runs/00000-stylegan3-t-portraits_256x256-gpus1-batch32-gamma6.6/network-snapshot-000040.pkl\"\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "\n",
            "Generator                     Parameters  Buffers  Output shape         Datatype\n",
            "---                           ---         ---      ---                  ---     \n",
            "mapping.fc0                   262656      -        [16, 512]            float32 \n",
            "mapping.fc1                   262656      -        [16, 512]            float32 \n",
            "mapping                       -           512      [16, 16, 512]        float32 \n",
            "synthesis.input.affine        2052        -        [16, 4]              float32 \n",
            "synthesis.input               262144      1545     [16, 512, 36, 36]    float32 \n",
            "synthesis.L0_36_512.affine    262656      -        [16, 512]            float32 \n",
            "synthesis.L0_36_512           2359808     25       [16, 512, 36, 36]    float32 \n",
            "synthesis.L1_36_512.affine    262656      -        [16, 512]            float32 \n",
            "synthesis.L1_36_512           2359808     25       [16, 512, 36, 36]    float32 \n",
            "synthesis.L2_36_512.affine    262656      -        [16, 512]            float32 \n",
            "synthesis.L2_36_512           2359808     25       [16, 512, 36, 36]    float32 \n",
            "synthesis.L3_52_512.affine    262656      -        [16, 512]            float32 \n",
            "synthesis.L3_52_512           2359808     37       [16, 512, 52, 52]    float16 \n",
            "synthesis.L4_52_512.affine    262656      -        [16, 512]            float32 \n",
            "synthesis.L4_52_512           2359808     25       [16, 512, 52, 52]    float16 \n",
            "synthesis.L5_84_512.affine    262656      -        [16, 512]            float32 \n",
            "synthesis.L5_84_512           2359808     37       [16, 512, 84, 84]    float16 \n",
            "synthesis.L6_84_512.affine    262656      -        [16, 512]            float32 \n",
            "synthesis.L6_84_512           2359808     25       [16, 512, 84, 84]    float16 \n",
            "synthesis.L7_148_512.affine   262656      -        [16, 512]            float32 \n",
            "synthesis.L7_148_512          2359808     37       [16, 512, 148, 148]  float16 \n",
            "synthesis.L8_148_512.affine   262656      -        [16, 512]            float32 \n",
            "synthesis.L8_148_512          2359808     25       [16, 512, 148, 148]  float16 \n",
            "synthesis.L9_148_362.affine   262656      -        [16, 512]            float32 \n",
            "synthesis.L9_148_362          1668458     25       [16, 362, 148, 148]  float16 \n",
            "synthesis.L10_276_256.affine  185706      -        [16, 362]            float32 \n",
            "synthesis.L10_276_256         834304      37       [16, 256, 276, 276]  float16 \n",
            "synthesis.L11_276_181.affine  131328      -        [16, 256]            float32 \n",
            "synthesis.L11_276_181         417205      25       [16, 181, 276, 276]  float16 \n",
            "synthesis.L12_276_128.affine  92853       -        [16, 181]            float32 \n",
            "synthesis.L12_276_128         208640      25       [16, 128, 276, 276]  float16 \n",
            "synthesis.L13_256_128.affine  65664       -        [16, 128]            float32 \n",
            "synthesis.L13_256_128         147584      25       [16, 128, 256, 256]  float16 \n",
            "synthesis.L14_256_3.affine    65664       -        [16, 128]            float32 \n",
            "synthesis.L14_256_3           387         1        [16, 3, 256, 256]    float16 \n",
            "synthesis                     -           -        [16, 3, 256, 256]    float32 \n",
            "---                           ---         ---      ---                  ---     \n",
            "Total                         28472133    2456     -                    -       \n",
            "\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape         Datatype\n",
            "---            ---         ---      ---                  ---     \n",
            "b256.fromrgb   512         16       [16, 128, 256, 256]  float16 \n",
            "b256.skip      32768       16       [16, 256, 128, 128]  float16 \n",
            "b256.conv0     147584      16       [16, 128, 256, 256]  float16 \n",
            "b256.conv1     295168      16       [16, 256, 128, 128]  float16 \n",
            "b256           -           16       [16, 256, 128, 128]  float16 \n",
            "b128.skip      131072      16       [16, 512, 64, 64]    float16 \n",
            "b128.conv0     590080      16       [16, 256, 128, 128]  float16 \n",
            "b128.conv1     1180160     16       [16, 512, 64, 64]    float16 \n",
            "b128           -           16       [16, 512, 64, 64]    float16 \n",
            "b64.skip       262144      16       [16, 512, 32, 32]    float16 \n",
            "b64.conv0      2359808     16       [16, 512, 64, 64]    float16 \n",
            "b64.conv1      2359808     16       [16, 512, 32, 32]    float16 \n",
            "b64            -           16       [16, 512, 32, 32]    float16 \n",
            "b32.skip       262144      16       [16, 512, 16, 16]    float16 \n",
            "b32.conv0      2359808     16       [16, 512, 32, 32]    float16 \n",
            "b32.conv1      2359808     16       [16, 512, 16, 16]    float16 \n",
            "b32            -           16       [16, 512, 16, 16]    float16 \n",
            "b16.skip       262144      16       [16, 512, 8, 8]      float32 \n",
            "b16.conv0      2359808     16       [16, 512, 16, 16]    float32 \n",
            "b16.conv1      2359808     16       [16, 512, 8, 8]      float32 \n",
            "b16            -           16       [16, 512, 8, 8]      float32 \n",
            "b8.skip        262144      16       [16, 512, 4, 4]      float32 \n",
            "b8.conv0       2359808     16       [16, 512, 8, 8]      float32 \n",
            "b8.conv1       2359808     16       [16, 512, 4, 4]      float32 \n",
            "b8             -           16       [16, 512, 4, 4]      float32 \n",
            "b4.mbstd       -           -        [16, 513, 4, 4]      float32 \n",
            "b4.conv        2364416     16       [16, 512, 4, 4]      float32 \n",
            "b4.fc          4194816     -        [16, 512]            float32 \n",
            "b4.out         513         -        [16, 1]              float32 \n",
            "---            ---         ---      ---                  ---     \n",
            "Total          28864129    416      -                    -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "2024-04-11 12:24:49.955529: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-11 12:24:49.955583: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-11 12:24:49.956868: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-11 12:24:51.103670: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Training for 500 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      time 10m 12s      sec/tick 237.8   sec/kimg 7430.45 maintenance 374.0  cpumem 3.13   gpumem 13.75  reserved 14.36  augment 0.000\n",
            "Evaluating metrics...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "{\"results\": {\"fid50k_full\": 286.22646388459214}, \"metric\": \"fid50k_full\", \"total_time\": 3246.4399478435516, \"total_time_str\": \"54m 06s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000000.pkl\", \"timestamp\": 1712841817.2176757}\n",
            "tick 1     kimg 4.0      time 1h 25m 49s   sec/tick 1249.3  sec/kimg 312.31  maintenance 3287.7 cpumem 3.52   gpumem 14.27  reserved 14.57  augment 0.003\n"
          ]
        }
      ],
      "source": [
        "!python /content/stylegan3/train.py --outdir=/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/experiments/portraits_256x256/training-runs \\\n",
        "    --cfg=stylegan3-t --data=/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/dataset/portraits_256x256.zip \\\n",
        "    --gpus=1 --batch=32 --batch-gpu=16 --metrics=fid50k_full --gamma=6.6 --mirror=1 --kimg=500 --snap=10 \\\n",
        "    --resume=/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/experiments/portraits_256x256/training-runs/00000-stylegan3-t-portraits_256x256-gpus1-batch32-gamma6.6/network-snapshot-000040.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yi2XIdd2qao",
        "outputId": "956c0a42-1a01-49fa-9c6c-30469446216f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading networks from \"/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/experiments/portraits_256x256/training-runs/00007-stylegan3-t-portraits_256x256-gpus1-batch32-gamma6.6/network-snapshot-000000.pkl\"...\n",
            "Generating image for seed 84 (0/4) ...\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "Generating image for seed 264 (1/4) ...\n",
            "Generating image for seed 296 (2/4) ...\n",
            "Generating image for seed 850 (3/4) ...\n"
          ]
        }
      ],
      "source": [
        "!python /content/stylegan3/gen_images.py --outdir=/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/experiments/portraits_256x256/out/model02 --trunc=1 --seeds=84,264,296,850 \\\n",
        "    --network=/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/experiments/portraits_256x256/training-runs/00007-stylegan3-t-portraits_256x256-gpus1-batch32-gamma6.6/network-snapshot-000000.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnbeTuaU4F6I",
        "outputId": "4c4a9e94-ba7c-48a3-e584-f599fca48622"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan3.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"magnitude_ema_beta\": 0.9988915792636801\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan2.Discriminator\",\n",
            "    \"block_kwargs\": {\n",
            "      \"freeze_layers\": 0\n",
            "    },\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.0025\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 6.6,\n",
            "    \"blur_init_sigma\": 0\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"prefetch_factor\": 2,\n",
            "    \"num_workers\": 3\n",
            "  },\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/dataset/portraits_256x256.zip\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 14965,\n",
            "    \"xflip\": true,\n",
            "    \"resolution\": 256,\n",
            "    \"random_seed\": 0\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"batch_size\": 32,\n",
            "  \"batch_gpu\": 16,\n",
            "  \"metrics\": [\n",
            "    \"fid50k_full\"\n",
            "  ],\n",
            "  \"total_kimg\": 300,\n",
            "  \"kimg_per_tick\": 4,\n",
            "  \"image_snapshot_ticks\": 10,\n",
            "  \"network_snapshot_ticks\": 10,\n",
            "  \"random_seed\": 0,\n",
            "  \"ema_kimg\": 10.0,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1,\n",
            "    \"brightness\": 1,\n",
            "    \"contrast\": 1,\n",
            "    \"lumaflip\": 1,\n",
            "    \"hue\": 1,\n",
            "    \"saturation\": 1\n",
            "  },\n",
            "  \"ada_target\": 0.6,\n",
            "  \"resume_pkl\": \"/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/experiments/portraits_256x256/training-runs/00002-stylegan3-t-portraits_256x256-gpus1-batch32-gamma6.6/network-snapshot-000000.pkl\",\n",
            "  \"ada_kimg\": 100,\n",
            "  \"ema_rampup\": null,\n",
            "  \"run_dir\": \"/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/experiments/portraits_256x256/training-runs/00003-stylegan3-t-portraits_256x256-gpus1-batch32-gamma6.6\"\n",
            "}\n",
            "\n",
            "Output directory:    /content/drive/MyDrive/GANsNFTs/StyleGAN/gan/experiments/portraits_256x256/training-runs/00003-stylegan3-t-portraits_256x256-gpus1-batch32-gamma6.6\n",
            "Number of GPUs:      1\n",
            "Batch size:          32 images\n",
            "Training duration:   300 kimg\n",
            "Dataset path:        /content/drive/MyDrive/GANsNFTs/StyleGAN/gan/dataset/portraits_256x256.zip\n",
            "Dataset size:        14965 images\n",
            "Dataset resolution:  256\n",
            "Dataset labels:      False\n",
            "Dataset x-flips:     True\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/sampler.py:64: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
            "  warnings.warn(\"`data_source` argument is not used and will be removed in 2.2.0.\"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "Num images:  29930\n",
            "Image shape: [3, 256, 256]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Resuming from \"/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/experiments/portraits_256x256/training-runs/00002-stylegan3-t-portraits_256x256-gpus1-batch32-gamma6.6/network-snapshot-000000.pkl\"\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "\n",
            "Generator                     Parameters  Buffers  Output shape         Datatype\n",
            "---                           ---         ---      ---                  ---     \n",
            "mapping.fc0                   262656      -        [16, 512]            float32 \n",
            "mapping.fc1                   262656      -        [16, 512]            float32 \n",
            "mapping                       -           512      [16, 16, 512]        float32 \n",
            "synthesis.input.affine        2052        -        [16, 4]              float32 \n",
            "synthesis.input               262144      1545     [16, 512, 36, 36]    float32 \n",
            "synthesis.L0_36_512.affine    262656      -        [16, 512]            float32 \n",
            "synthesis.L0_36_512           2359808     25       [16, 512, 36, 36]    float32 \n",
            "synthesis.L1_36_512.affine    262656      -        [16, 512]            float32 \n",
            "synthesis.L1_36_512           2359808     25       [16, 512, 36, 36]    float32 \n",
            "synthesis.L2_36_512.affine    262656      -        [16, 512]            float32 \n",
            "synthesis.L2_36_512           2359808     25       [16, 512, 36, 36]    float32 \n",
            "synthesis.L3_52_512.affine    262656      -        [16, 512]            float32 \n",
            "synthesis.L3_52_512           2359808     37       [16, 512, 52, 52]    float16 \n",
            "synthesis.L4_52_512.affine    262656      -        [16, 512]            float32 \n",
            "synthesis.L4_52_512           2359808     25       [16, 512, 52, 52]    float16 \n",
            "synthesis.L5_84_512.affine    262656      -        [16, 512]            float32 \n",
            "synthesis.L5_84_512           2359808     37       [16, 512, 84, 84]    float16 \n",
            "synthesis.L6_84_512.affine    262656      -        [16, 512]            float32 \n",
            "synthesis.L6_84_512           2359808     25       [16, 512, 84, 84]    float16 \n",
            "synthesis.L7_148_512.affine   262656      -        [16, 512]            float32 \n",
            "synthesis.L7_148_512          2359808     37       [16, 512, 148, 148]  float16 \n",
            "synthesis.L8_148_512.affine   262656      -        [16, 512]            float32 \n",
            "synthesis.L8_148_512          2359808     25       [16, 512, 148, 148]  float16 \n",
            "synthesis.L9_148_362.affine   262656      -        [16, 512]            float32 \n",
            "synthesis.L9_148_362          1668458     25       [16, 362, 148, 148]  float16 \n",
            "synthesis.L10_276_256.affine  185706      -        [16, 362]            float32 \n",
            "synthesis.L10_276_256         834304      37       [16, 256, 276, 276]  float16 \n",
            "synthesis.L11_276_181.affine  131328      -        [16, 256]            float32 \n",
            "synthesis.L11_276_181         417205      25       [16, 181, 276, 276]  float16 \n",
            "synthesis.L12_276_128.affine  92853       -        [16, 181]            float32 \n",
            "synthesis.L12_276_128         208640      25       [16, 128, 276, 276]  float16 \n",
            "synthesis.L13_256_128.affine  65664       -        [16, 128]            float32 \n",
            "synthesis.L13_256_128         147584      25       [16, 128, 256, 256]  float16 \n",
            "synthesis.L14_256_3.affine    65664       -        [16, 128]            float32 \n",
            "synthesis.L14_256_3           387         1        [16, 3, 256, 256]    float16 \n",
            "synthesis                     -           -        [16, 3, 256, 256]    float32 \n",
            "---                           ---         ---      ---                  ---     \n",
            "Total                         28472133    2456     -                    -       \n",
            "\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape         Datatype\n",
            "---            ---         ---      ---                  ---     \n",
            "b256.fromrgb   512         16       [16, 128, 256, 256]  float16 \n",
            "b256.skip      32768       16       [16, 256, 128, 128]  float16 \n",
            "b256.conv0     147584      16       [16, 128, 256, 256]  float16 \n",
            "b256.conv1     295168      16       [16, 256, 128, 128]  float16 \n",
            "b256           -           16       [16, 256, 128, 128]  float16 \n",
            "b128.skip      131072      16       [16, 512, 64, 64]    float16 \n",
            "b128.conv0     590080      16       [16, 256, 128, 128]  float16 \n",
            "b128.conv1     1180160     16       [16, 512, 64, 64]    float16 \n",
            "b128           -           16       [16, 512, 64, 64]    float16 \n",
            "b64.skip       262144      16       [16, 512, 32, 32]    float16 \n",
            "b64.conv0      2359808     16       [16, 512, 64, 64]    float16 \n",
            "b64.conv1      2359808     16       [16, 512, 32, 32]    float16 \n",
            "b64            -           16       [16, 512, 32, 32]    float16 \n",
            "b32.skip       262144      16       [16, 512, 16, 16]    float16 \n",
            "b32.conv0      2359808     16       [16, 512, 32, 32]    float16 \n",
            "b32.conv1      2359808     16       [16, 512, 16, 16]    float16 \n",
            "b32            -           16       [16, 512, 16, 16]    float16 \n",
            "b16.skip       262144      16       [16, 512, 8, 8]      float32 \n",
            "b16.conv0      2359808     16       [16, 512, 16, 16]    float32 \n",
            "b16.conv1      2359808     16       [16, 512, 8, 8]      float32 \n",
            "b16            -           16       [16, 512, 8, 8]      float32 \n",
            "b8.skip        262144      16       [16, 512, 4, 4]      float32 \n",
            "b8.conv0       2359808     16       [16, 512, 8, 8]      float32 \n",
            "b8.conv1       2359808     16       [16, 512, 4, 4]      float32 \n",
            "b8             -           16       [16, 512, 4, 4]      float32 \n",
            "b4.mbstd       -           -        [16, 513, 4, 4]      float32 \n",
            "b4.conv        2364416     16       [16, 512, 4, 4]      float32 \n",
            "b4.fc          4194816     -        [16, 512]            float32 \n",
            "b4.out         513         -        [16, 1]              float32 \n",
            "---            ---         ---      ---                  ---     \n",
            "Total          28864129    416      -                    -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "2024-04-12 09:20:00.992031: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-12 09:20:00.992084: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-12 09:20:00.993412: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-12 09:20:02.144224: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Training for 300 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      time 10m 34s      sec/tick 221.5   sec/kimg 6920.94 maintenance 413.0  cpumem 3.12   gpumem 13.75  reserved 14.44  augment 0.000\n",
            "Evaluating metrics...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "{\"results\": {\"fid50k_full\": 286.4358185477901}, \"metric\": \"fid50k_full\", \"total_time\": 2947.5467162132263, \"total_time_str\": \"49m 08s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000000.pkl\", \"timestamp\": 1712916814.217933}\n"
          ]
        }
      ],
      "source": [
        "!python /content/stylegan3/train.py --outdir=/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/experiments/portraits_256x256/training-runs \\\n",
        "    --cfg=stylegan3-t --data=/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/dataset/portraits_256x256.zip \\\n",
        "    --gpus=1 --batch=32 --batch-gpu=16 --metrics=fid50k_full --gamma=6.6 --mirror=1 --kimg=300 --snap=10 \\\n",
        "    --resume=/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/experiments/portraits_256x256/training-runs/00002-stylegan3-t-portraits_256x256-gpus1-batch32-gamma6.6/network-snapshot-000000.pkl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afZrNKyZhGgA"
      },
      "source": [
        "###Resume without metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYE7noiugyqj",
        "outputId": "1f241d9c-54b9-487d-8118-0f76eed9638e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan3.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"magnitude_ema_beta\": 0.9988915792636801\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan2.Discriminator\",\n",
            "    \"block_kwargs\": {\n",
            "      \"freeze_layers\": 0\n",
            "    },\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.0025\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 6.6,\n",
            "    \"blur_init_sigma\": 0\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"prefetch_factor\": 2,\n",
            "    \"num_workers\": 3\n",
            "  },\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/dataset/portraits_256x256.zip\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 14965,\n",
            "    \"xflip\": true,\n",
            "    \"resolution\": 256,\n",
            "    \"random_seed\": 0\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"batch_size\": 32,\n",
            "  \"batch_gpu\": 16,\n",
            "  \"metrics\": [],\n",
            "  \"total_kimg\": 300,\n",
            "  \"kimg_per_tick\": 4,\n",
            "  \"image_snapshot_ticks\": 10,\n",
            "  \"network_snapshot_ticks\": 10,\n",
            "  \"random_seed\": 0,\n",
            "  \"ema_kimg\": 10.0,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1,\n",
            "    \"brightness\": 1,\n",
            "    \"contrast\": 1,\n",
            "    \"lumaflip\": 1,\n",
            "    \"hue\": 1,\n",
            "    \"saturation\": 1\n",
            "  },\n",
            "  \"ada_target\": 0.6,\n",
            "  \"resume_pkl\": \"/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/experiments/portraits_256x256/training-runs/00003-stylegan3-t-portraits_256x256-gpus1-batch32-gamma6.6/network-snapshot-000000.pkl\",\n",
            "  \"ada_kimg\": 100,\n",
            "  \"ema_rampup\": null,\n",
            "  \"run_dir\": \"/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/experiments/portraits_256x256/training-runs/00007-stylegan3-t-portraits_256x256-gpus1-batch32-gamma6.6\"\n",
            "}\n",
            "\n",
            "Output directory:    /content/drive/MyDrive/GANsNFTs/StyleGAN/gan/experiments/portraits_256x256/training-runs/00007-stylegan3-t-portraits_256x256-gpus1-batch32-gamma6.6\n",
            "Number of GPUs:      1\n",
            "Batch size:          32 images\n",
            "Training duration:   300 kimg\n",
            "Dataset path:        /content/drive/MyDrive/GANsNFTs/StyleGAN/gan/dataset/portraits_256x256.zip\n",
            "Dataset size:        14965 images\n",
            "Dataset resolution:  256\n",
            "Dataset labels:      False\n",
            "Dataset x-flips:     True\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/sampler.py:64: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
            "  warnings.warn(\"`data_source` argument is not used and will be removed in 2.2.0.\"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "Num images:  29930\n",
            "Image shape: [3, 256, 256]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Resuming from \"/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/experiments/portraits_256x256/training-runs/00003-stylegan3-t-portraits_256x256-gpus1-batch32-gamma6.6/network-snapshot-000000.pkl\"\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "\n",
            "Generator                     Parameters  Buffers  Output shape         Datatype\n",
            "---                           ---         ---      ---                  ---     \n",
            "mapping.fc0                   262656      -        [16, 512]            float32 \n",
            "mapping.fc1                   262656      -        [16, 512]            float32 \n",
            "mapping                       -           512      [16, 16, 512]        float32 \n",
            "synthesis.input.affine        2052        -        [16, 4]              float32 \n",
            "synthesis.input               262144      1545     [16, 512, 36, 36]    float32 \n",
            "synthesis.L0_36_512.affine    262656      -        [16, 512]            float32 \n",
            "synthesis.L0_36_512           2359808     25       [16, 512, 36, 36]    float32 \n",
            "synthesis.L1_36_512.affine    262656      -        [16, 512]            float32 \n",
            "synthesis.L1_36_512           2359808     25       [16, 512, 36, 36]    float32 \n",
            "synthesis.L2_36_512.affine    262656      -        [16, 512]            float32 \n",
            "synthesis.L2_36_512           2359808     25       [16, 512, 36, 36]    float32 \n",
            "synthesis.L3_52_512.affine    262656      -        [16, 512]            float32 \n",
            "synthesis.L3_52_512           2359808     37       [16, 512, 52, 52]    float16 \n",
            "synthesis.L4_52_512.affine    262656      -        [16, 512]            float32 \n",
            "synthesis.L4_52_512           2359808     25       [16, 512, 52, 52]    float16 \n",
            "synthesis.L5_84_512.affine    262656      -        [16, 512]            float32 \n",
            "synthesis.L5_84_512           2359808     37       [16, 512, 84, 84]    float16 \n",
            "synthesis.L6_84_512.affine    262656      -        [16, 512]            float32 \n",
            "synthesis.L6_84_512           2359808     25       [16, 512, 84, 84]    float16 \n",
            "synthesis.L7_148_512.affine   262656      -        [16, 512]            float32 \n",
            "synthesis.L7_148_512          2359808     37       [16, 512, 148, 148]  float16 \n",
            "synthesis.L8_148_512.affine   262656      -        [16, 512]            float32 \n",
            "synthesis.L8_148_512          2359808     25       [16, 512, 148, 148]  float16 \n",
            "synthesis.L9_148_362.affine   262656      -        [16, 512]            float32 \n",
            "synthesis.L9_148_362          1668458     25       [16, 362, 148, 148]  float16 \n",
            "synthesis.L10_276_256.affine  185706      -        [16, 362]            float32 \n",
            "synthesis.L10_276_256         834304      37       [16, 256, 276, 276]  float16 \n",
            "synthesis.L11_276_181.affine  131328      -        [16, 256]            float32 \n",
            "synthesis.L11_276_181         417205      25       [16, 181, 276, 276]  float16 \n",
            "synthesis.L12_276_128.affine  92853       -        [16, 181]            float32 \n",
            "synthesis.L12_276_128         208640      25       [16, 128, 276, 276]  float16 \n",
            "synthesis.L13_256_128.affine  65664       -        [16, 128]            float32 \n",
            "synthesis.L13_256_128         147584      25       [16, 128, 256, 256]  float16 \n",
            "synthesis.L14_256_3.affine    65664       -        [16, 128]            float32 \n",
            "synthesis.L14_256_3           387         1        [16, 3, 256, 256]    float16 \n",
            "synthesis                     -           -        [16, 3, 256, 256]    float32 \n",
            "---                           ---         ---      ---                  ---     \n",
            "Total                         28472133    2456     -                    -       \n",
            "\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape         Datatype\n",
            "---            ---         ---      ---                  ---     \n",
            "b256.fromrgb   512         16       [16, 128, 256, 256]  float16 \n",
            "b256.skip      32768       16       [16, 256, 128, 128]  float16 \n",
            "b256.conv0     147584      16       [16, 128, 256, 256]  float16 \n",
            "b256.conv1     295168      16       [16, 256, 128, 128]  float16 \n",
            "b256           -           16       [16, 256, 128, 128]  float16 \n",
            "b128.skip      131072      16       [16, 512, 64, 64]    float16 \n",
            "b128.conv0     590080      16       [16, 256, 128, 128]  float16 \n",
            "b128.conv1     1180160     16       [16, 512, 64, 64]    float16 \n",
            "b128           -           16       [16, 512, 64, 64]    float16 \n",
            "b64.skip       262144      16       [16, 512, 32, 32]    float16 \n",
            "b64.conv0      2359808     16       [16, 512, 64, 64]    float16 \n",
            "b64.conv1      2359808     16       [16, 512, 32, 32]    float16 \n",
            "b64            -           16       [16, 512, 32, 32]    float16 \n",
            "b32.skip       262144      16       [16, 512, 16, 16]    float16 \n",
            "b32.conv0      2359808     16       [16, 512, 32, 32]    float16 \n",
            "b32.conv1      2359808     16       [16, 512, 16, 16]    float16 \n",
            "b32            -           16       [16, 512, 16, 16]    float16 \n",
            "b16.skip       262144      16       [16, 512, 8, 8]      float32 \n",
            "b16.conv0      2359808     16       [16, 512, 16, 16]    float32 \n",
            "b16.conv1      2359808     16       [16, 512, 8, 8]      float32 \n",
            "b16            -           16       [16, 512, 8, 8]      float32 \n",
            "b8.skip        262144      16       [16, 512, 4, 4]      float32 \n",
            "b8.conv0       2359808     16       [16, 512, 8, 8]      float32 \n",
            "b8.conv1       2359808     16       [16, 512, 4, 4]      float32 \n",
            "b8             -           16       [16, 512, 4, 4]      float32 \n",
            "b4.mbstd       -           -        [16, 513, 4, 4]      float32 \n",
            "b4.conv        2364416     16       [16, 512, 4, 4]      float32 \n",
            "b4.fc          4194816     -        [16, 512]            float32 \n",
            "b4.out         513         -        [16, 1]              float32 \n",
            "---            ---         ---      ---                  ---     \n",
            "Total          28864129    416      -                    -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "2024-04-13 10:47:39.284873: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-13 10:47:39.284936: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-13 10:47:39.286841: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-13 10:47:40.642719: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Training for 300 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      time 9m 59s       sec/tick 221.5   sec/kimg 6921.34 maintenance 377.4  cpumem 3.12   gpumem 13.75  reserved 14.28  augment 0.000\n",
            "tick 1     kimg 4.0      time 30m 14s      sec/tick 1172.9  sec/kimg 293.23  maintenance 42.0   cpumem 3.34   gpumem 10.03  reserved 13.78  augment 0.004\n",
            "tick 2     kimg 8.0      time 49m 48s      sec/tick 1174.3  sec/kimg 293.57  maintenance 0.4    cpumem 3.34   gpumem 10.03  reserved 13.78  augment 0.001\n"
          ]
        }
      ],
      "source": [
        "!python /content/stylegan3/train.py --outdir=/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/experiments/portraits_256x256/training-runs \\\n",
        "    --cfg=stylegan3-t --data=/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/dataset/portraits_256x256.zip \\\n",
        "    --gpus=1 --batch=32 --batch-gpu=16 --metrics=none --gamma=6.6 --mirror=1 --kimg=300 --snap=10 \\\n",
        "    --resume=/content/drive/MyDrive/GANsNFTs/StyleGAN/gan/experiments/portraits_256x256/training-runs/00003-stylegan3-t-portraits_256x256-gpus1-batch32-gamma6.6/network-snapshot-000000.pkl"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "hxoIoG_rlsny"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}